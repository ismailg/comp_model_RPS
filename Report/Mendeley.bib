@article{spiliopoulos2013strategic,
author = {Spiliopoulos, Leonidas},
journal = {Autonomous agents and multi-agent systems},
number = {1},
pages = {131--160},
publisher = {Springer},
title = {{Strategic adaptation of humans playing computer algorithms in a repeated constant-sum game}},
volume = {27},
year = {2013}
}
@article{Juvina2015,
abstract = {We present a computational cognitive model that explains transfer of learning across two games of strategic interaction - Prisoner's Dilemma and Chicken. We summarize prior research showing that, when these games are played in sequence, the experience acquired in the first game influences the players' behavior in the second game. The same model accounts for human data in both games. The model explains transfer effects with the aid of a trust mechanism that determines how rewards change depending on the dynamics of the interaction between players. We conclude that factors pertaining to the game or the individual are insufficient to explain the whole range of transfer effects and factors pertaining to the interaction between players should be considered as well.},
author = {Juvina, Ion and Lebiere, Christian and Gonzalez, Cleotilde},
doi = {10.1016/j.jarmac.2014.09.004},
file = {:home/ismail/Documents/Literature learning transfer/Juvina{\_}2014.pdf:pdf},
issn = {22113681},
journal = {Journal of Applied Research in Memory and Cognition},
keywords = {Cognitive modeling,Social dilemmas,Strategic interaction,Transfer of learning,Trust dynamics},
number = {3},
pages = {197--211},
publisher = {The Society for Applied Research in Memory and Cognition},
title = {{Modeling trust dynamics in strategic interaction}},
url = {http://dx.doi.org/10.1016/j.jarmac.2014.09.004},
volume = {4},
year = {2015}
}
@article{Lake2017,
abstract = {Recent progress in artificial intelligence has renewed interest in building systems that learn and think like people. Many advances have come from using deep neural networks trained end-to-end in tasks such as object recognition, video games, and board games, achieving performance that equals or even beats that of humans in some respects. Despite their biological inspiration and performance achievements, these systems differ from human intelligence in crucial ways. We review progress in cognitive science suggesting that truly human-like learning and thinking machines will have to reach beyond current engineering trends in both what they learn and how they learn it. Specifically, we argue that these machines should (1) build causal models of the world that support explanation and understanding, rather than merely solving pattern recognition problems; (2) ground learning in intuitive theories of physics and psychology to support and enrich the knowledge that is learned; and (3) harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations. We suggest concrete challenges and promising routes toward these goals that can combine the strengths of recent neural network advances with more structured cognitive models.},
archivePrefix = {arXiv},
arxivId = {1604.00289},
author = {Lake, Brenden M. and Ullman, Tomer D. and Tenenbaum, Joshua B. and Gershman, Samuel J.},
doi = {10.1017/S0140525X16001837},
eprint = {1604.00289},
issn = {14691825},
journal = {Behavioral and Brain Sciences},
publisher = {Cambridge University Press},
title = {{Building machines that learn and think like people}},
volume = {40},
year = {2017}
}
@article{Rick2010,
abstract = {Psychologists have long recognized two kinds of learning: one that is relatively shallow and domain-specific; and another that is deeper, producing generalizable insights that transfer across domains. The game theory literature has only recently considered this distinction, and the conditions that stimulate the latter kind of "meaningful" learning in games are still unclear. Three experiments demonstrate that one kind of meaningful learning - acquisition of iterated dominance - occurs in the absence of any feedback. We demonstrate that such feedback-free meaningful learning transfers to new strategically similar games, and that such transfer does not typically occur when initial games are played with feedback. The effects of withholding feedback are similar to, and substitutable with, those produced by requiring players to explain their behavior, a method commonly employed in psychology to increase deliberation. This similarity suggests that withholding feedback encourages deeper thinking about the game in a manner similar to such self-explanation. {\textcopyright} 2009 Elsevier Inc. All rights reserved.},
author = {Rick, Scott and Weber, Roberto A.},
doi = {10.1016/j.geb.2009.10.004},
file = {:home/ismail/Documents/Literature learning transfer/Rick{\_}weber{\_}learn{\_}transfer{\_}2008.pdf:pdf},
issn = {08998256},
journal = {Games and Economic Behavior},
number = {2},
pages = {716--730},
publisher = {Elsevier Inc.},
title = {{Meaningful learning and transfer of learning in games played repeatedly without feedback}},
url = {http://dx.doi.org/10.1016/j.geb.2009.10.004},
volume = {68},
year = {2010}
}
@inproceedings{de2012higher,
author = {de Weerd, Harmen and Verbrugge, Rineke and Verheij, Bart},
booktitle = {Proceedings of the 11th International Conference on Autonomous Agents and Multiagent Systems-Volume 3},
pages = {1195--1196},
title = {{Higher-order social cognition in rock-paper-scissors: A simulation study}},
year = {2012}
}
@article{Juvina2013,
abstract = {We studied transfer of learning across two games of strategic interaction. We found that the interpersonal relation between two players during and across two games influence development of reciprocal trust and transfer of learning from one game to another. We show that two types of similarities between the games affect transfer: (1) deep similarities facilitate transfer of an optimal solution across games; (2) surface similarities can either facilitate or hinder transfer depending on whether they lead players toward an optimal or sub-optimal solution in the target game. Learning an optimal solution in a context of interdependence between players is associated with development of reciprocal trust, which in turn mediates transfer of learning across games. The results can be used to inform the design of training exercises to develop strategic interaction skills. {\textcopyright} 2012 Elsevier Inc.},
author = {Juvina, Ion and Saleem, Muniba and Martin, Jolie M. and Gonzalez, Cleotilde and Lebiere, Christian},
doi = {10.1016/j.obhdp.2012.09.004},
file = {:home/ismail/Documents/Literature learning transfer/Juvina{\_}2013.pdf:pdf},
issn = {07495978},
journal = {Organizational Behavior and Human Decision Processes},
keywords = {Cooperation,Games of strategic interaction,Reciprocal trust,Surface and deep similarities,Transfer of learning},
number = {2},
pages = {206--215},
publisher = {Elsevier Inc.},
title = {{Reciprocal trust mediates deep transfer of learning between games of strategic interaction}},
url = {http://dx.doi.org/10.1016/j.obhdp.2012.09.004},
volume = {120},
year = {2013}
}
@article{Woodruff,
author = {Woodruff, G and Sciences, D Premack - Behavioral and Brain and undefined 1978},
title = {{Does the chimpanzee have a theory of mind}}
}
@article{Vickery2015,
abstract = {Context plays a pivotal role in many decision-making scenarios, including social interactions wherein the identities and strategies of other decision makers often shape our behaviors. However, the neural mechanisms for tracking such contextual information are poorly understood. Here, we investigated how opponent identity affects human reinforcement learning during a simulated competitive game against two independent computerized opponents. We found that strategies of participants were affected preferentially by the outcomes of the previous interactions with the same opponent. In addition, reinforcement signals from the previous trial were less discriminable throughout the brain after the opponent changed, compared with when the same opponent was repeated. These opponent-selective reinforcement signals were particularly robust in right rostral anterior cingulate and right lingual regions, where opponent-selective reinforcement signals correlated with a behavioral measure of opponent-selective reinforcement learning. Therefore, when choices involve multiple contextual frames, such as different opponents in a game, decision making and its neural correlates are influenced by multithreaded histories of reinforcement. Overall, our findings are consistent with the availability of temporally overlapping, contextspecific reinforcement signals.},
author = {Vickery, Timothy J. and Kleinman, Matthew R. and Chun, Marvin M. and Lee, Daeyeol},
doi = {10.1523/JNEUROSCI.3530-14.2015},
file = {:home/ismail/Documents/Literature learning transfer/vickery{\_}15{\_}neuro{\_}opp{\_}id:},
issn = {15292401},
journal = {Journal of Neuroscience},
keywords = {Decision making,FMRI,Games,Reinforcement},
number = {31},
pages = {11133--11143},
title = {{Opponent identity influences value learning in simple games}},
volume = {35},
year = {2015}
}
@article{ho2004economics,
author = {Ho, Teck H and Camerer, Colin F and Chong, Juin-Kuan},
publisher = {California Institute of Technology},
title = {{The economics of learning models: A self-tuning theory of learning in games}},
year = {2004}
}
@article{Ioannou2014,
abstract = {We propose a methodology that is generalizable to a broad class of repeated games in order to facilitate operability of belief-learning models with repeated-game strategies. The methodology consists of (1) a generalized repeated-game strategy space, (2) a mapping between histories and repeated-game beliefs, and (3) asynchronous updating of repeated-game strategies. We implement the proposed methodology by building on three proven action-learning models. Their predictions with repeated-game strategies are then validated with data from experiments with human subjects in four, symmetric 2 × 2 games: Prisoner's Dilemma, Battle of the Sexes, Stag-Hunt, and Chicken. The models with repeated-game strategies approximate subjects' behavior substantially better than their respective models with action learning. Additionally, inferred rules of behavior in the experimental data overlap with the predicted rules of behavior. {\textcopyright} 2014 Elsevier Inc.},
author = {Ioannou, Christos A. and Romero, Julian},
doi = {10.1016/j.geb.2014.05.007},
file = {:home/ismail/Documents/Literature learning transfer/Ioannou2014{\_}rule{\_}learning.pdf:pdf},
issn = {10902473},
journal = {Games and Economic Behavior},
keywords = {Adaptive models,Battle of the Sexes,Belief learning,Chicken,Finite automata,Prisoner's Dilemma,Repeated-game strategies,Stag-Hunt},
pages = {178--203},
publisher = {Elsevier Inc.},
title = {{A generalized approach to belief learning in repeated games}},
url = {http://dx.doi.org/10.1016/j.geb.2014.05.007},
volume = {87},
year = {2014}
}
@article{simon1972theories,
author = {Simon, Herbert A},
journal = {Decision and organization},
number = {1},
pages = {161--176},
publisher = {North-Holland},
title = {{Theories of bounded rationality}},
volume = {1},
year = {1972}
}
@incollection{mertens1990repeated,
author = {Mertens, Jean-Fran{\c{c}}ois},
booktitle = {Game Theory and Applications},
pages = {77--130},
publisher = {Elsevier},
title = {{Repeated games}},
year = {1990}
}
@article{Cooper2008,
abstract = {We explore how learning to play strategically in one signaling game promotes strategic play in a related signaling game. Following convergence to a pooling equilibrium, payoffs are changed to only support separating equilibria. More strategic play is observed following the change in payoffs than for inexperienced subjects in control sessions, contrary to the prediction of a fictitious play learning model. Introducing a growing proportion of sophisticated learners, subjects who anticipate responders' behavior following the change in payoffs, enables the model to capture the positive cross-game learning observed in the data. {\textcopyright} 2007 Springer-Verlag.},
author = {Cooper, David J. and Kagel, John H.},
doi = {10.1007/s00199-006-0192-5},
file = {:home/ismail/Documents/Literature learning transfer/Cooper-Kagel2008{\_}Article{\_}LearningAndTransferInSignaling.pdf:pdf},
isbn = {1216368503},
issn = {09382259},
journal = {Economic Theory},
keywords = {Cross-game learning,Experiment,Learning,Learning transfer,Signaling games},
number = {3},
pages = {415--439},
title = {{Learning and transfer in signaling games}},
volume = {34},
year = {2008}
}
@article{watkins1992q,
author = {Watkins, Christopher J C H and Dayan, Peter},
journal = {Machine learning},
number = {3-4},
pages = {279--292},
publisher = {Springer},
title = {{Q-learning}},
volume = {8},
year = {1992}
}
@article{Haruvy2012,
abstract = {Rule learning posits that decision makers, rather than choosing over actions, choose over behavioral rules with different levels of sophistication. Rules are reinforced over time based on their historically observed payoffs in a given game. Past works on rule learning have shown that when playing a single game over a number of rounds, players can learn to form sophisticated beliefs about others. Here we are interested in learning that occurs between games where the set of actions is not directly comparable from one game to the next. We study a sequence of ten thrice-played dissimilar games. Using experimental data, we find that our rule learning model captures the ability of players to learn to reason across games. However, this learning appears different from within-game rule learning as previously documented. The main adjustment in sophistication occurs by switching from non-belief-based strategies to belief-based strategies. The sophistication of the beliefs themselves increases only slightly over time. {\textcopyright} 2011 Elsevier Inc.},
author = {Haruvy, Ernan and Stahl, Dale O.},
doi = {10.1016/j.geb.2011.06.001},
file = {:home/ismail/Documents/Literature learning transfer/Haruvy{\_}Stahl{\_}2012.pdf:pdf},
issn = {08998256},
journal = {Games and Economic Behavior},
keywords = {Experiments,Learning,Transference},
number = {1},
pages = {208--221},
publisher = {Elsevier Inc.},
title = {{Between-game rule learning in dissimilar symmetric normal-form games}},
url = {http://dx.doi.org/10.1016/j.geb.2011.06.001},
volume = {74},
year = {2012}
}
@article{perkins1992transfer,
author = {Perkins, David N and Salomon, Gavriel and Others},
journal = {International encyclopedia of education},
pages = {6452--6457},
publisher = {Citeseer},
title = {{Transfer of learning}},
volume = {2},
year = {1992}
}
@book{cheung1994learning,
author = {Cheung, Yin-Wong and Friedman, Daniel},
publisher = {University of California, Santa Cruz},
title = {{Learning in evolutionary games: some laboratory results}},
year = {1994}
}
@article{knez2000increasing,
  title={Increasing cooperation in prisoner's dilemmas by establishing a precedent of efficiency in coordination games},
  author={Knez, Marc and Camerer, Colin},
  journal={Organizational Behavior and Human Decision Processes},
  volume={82},
  number={2},
  pages={194--216},
  year={2000},
  publisher={Elsevier}
}
@article{ho1998iterated,
author = {Ho, Teck-Hua and Camerer, Colin and Weigelt, Keith},
journal = {The American Economic Review},
number = {4},
pages = {947--969},
publisher = {JSTOR},
title = {{Iterated dominance and iterated best response in experimental" p-beauty contests"}},
volume = {88},
year = {1998}
}
@article{goodie2012levels,
author = {Goodie, Adam S and Doshi, Prashant and Young, Diana L},
journal = {Journal of Behavioral Decision Making},
number = {1},
pages = {95--108},
publisher = {Wiley Online Library},
title = {{Levels of theory-of-mind reasoning in competitive games}},
volume = {25},
year = {2012}
}
@article{stahl1995players,
author = {Stahl, Dale O and Wilson, Paul W},
journal = {Games and Economic Behavior},
number = {1},
pages = {218--254},
publisher = {Elsevier},
title = {{On players models of other players: Theory and experimental evidence}},
volume = {10},
year = {1995}
}
@article{shachat2004we,
author = {Shachat, Jason and Swarthout, J Todd},
journal = {Mathematical Methods of Operations Research},
number = {3},
pages = {359--373},
publisher = {Springer},
title = {{Do we detect and exploit mixed strategy play by opponents?}},
volume = {59},
year = {2004}
}
@techreport{camerer1997experience,
author = {Camerer, Colin and Ho, Teck-Hua and Others},
title = {{Experience-weighted attraction learning in games: A unifying approach}},
year = {1997}
}
@article{cooper2003lessons,
author = {Cooper, David J and Kagel, John H},
journal = {American Economic Review},
number = {2},
pages = {202--207},
title = {{Lessons learned: generalizing learning across games}},
volume = {93},
year = {2003}
}
@article{arad201211,
author = {Arad, Ayala and Rubinstein, Ariel},
journal = {American Economic Review},
number = {7},
pages = {3561--3573},
title = {{The 11-20 money request game: A level-k reasoning study}},
volume = {102},
year = {2012}
}
@article{Stahl2008,
author = {Stahl, Dale O},
file = {:home/ismail/Documents/Literature learning transfer/Haruvy{\_}Stahl{\_}2009.pdf:pdf},
keywords = {experiments,learning,transference},
title = {{Learning Transference Between Dissimilar Symmetric Normal-Form Games}},
year = {2008}
}
@article{baarslag2016learning,
author = {Baarslag, Tim and Hendrikx, Mark J C and Hindriks, Koen V and Jonker, Catholijn M},
journal = {Autonomous Agents and Multi-Agent Systems},
number = {5},
pages = {849--898},
publisher = {Springer},
title = {{Learning about the opponent in automated bilateral negotiation: a comprehensive survey of opponent modeling techniques}},
volume = {30},
year = {2016}
}
@Manual{R-afex,
  title = {afex: Analysis of Factorial Experiments},
  author = {Henrik Singmann and Ben Bolker and Jake Westfall and Frederik Aust and Mattan S. Ben-Shachar},
  year = {2019},
  note = {R package version 0.25-1},
  url = {https://CRAN.R-project.org/package=afex},
}
@Manual{R-base,
  title = {R: A Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  organization = {R Foundation for Statistical Computing},
  address = {Vienna, Austria},
  year = {2019},
  url = {https://www.R-project.org/},
}
@Book{R-bookdown,
  title = {bookdown: Authoring Books and Technical Documents with {R} Markdown},
  author = {Yihui Xie},
  publisher = {Chapman and Hall/CRC},
  address = {Boca Raton, Florida},
  year = {2016},
  note = {ISBN 978-1138700109},
  url = {https://github.com/rstudio/bookdown},
}
@Manual{R-citr,
  title = {citr: 'RStudio' Add-in to Insert Markdown Citations},
  author = {Frederik Aust},
  year = {2019},
  note = {R package version 0.3.2},
  url = {https://CRAN.R-project.org/package=citr},
}
@Manual{R-dplyr,
  title = {dplyr: A Grammar of Data Manipulation},
  author = {Hadley Wickham and Romain François and Lionel Henry and Kirill Müller},
  year = {2019},
  note = {R package version 0.8.3},
  url = {https://CRAN.R-project.org/package=dplyr},
}
@Manual{R-emmeans,
  title = {emmeans: Estimated Marginal Means, aka Least-Squares Means},
  author = {Russell Lenth},
  year = {2019},
  note = {R package version 1.4.3.01},
  url = {https://CRAN.R-project.org/package=emmeans},
}
@Book{R-ggplot2,
  author = {Hadley Wickham},
  title = {ggplot2: Elegant Graphics for Data Analysis},
  publisher = {Springer-Verlag New York},
  year = {2016},
  isbn = {978-3-319-24277-4},
  url = {https://ggplot2.tidyverse.org},
}
@Manual{R-ggpubr,
  title = {ggpubr: 'ggplot2' Based Publication Ready Plots},
  author = {Alboukadel Kassambara},
  year = {2019},
  note = {R package version 0.2.4},
  url = {https://CRAN.R-project.org/package=ggpubr},
}
@Manual{R-gld,
  title = {gld: Estimation and Use of the Generalised (Tukey) Lambda
Distribution},
  author = {Robert King and Benjamin Dean and Sigbert Klinke and Paul {van Staden}},
  year = {2019},
  note = {R package version 2.6},
  url = {https://CRAN.R-project.org/package=gld},
}
@Book{R-knitr,
  title = {Dynamic Documents with {R} and knitr},
  author = {Yihui Xie},
  publisher = {Chapman and Hall/CRC},
  address = {Boca Raton, Florida},
  year = {2015},
  edition = {2nd},
  note = {ISBN 978-1498716963},
  url = {https://yihui.name/knitr/},
}
@Book{R-lattice,
  title = {Lattice: Multivariate Data Visualization with R},
  author = {Deepayan Sarkar},
  publisher = {Springer},
  address = {New York},
  year = {2008},
  note = {ISBN 978-0-387-75968-5},
  url = {http://lmdvr.r-forge.r-project.org},
}
@Article{R-lme4,
  title = {Fitting Linear Mixed-Effects Models Using {lme4}},
  author = {Douglas Bates and Martin M{\"a}chler and Ben Bolker and Steve Walker},
  journal = {Journal of Statistical Software},
  year = {2015},
  volume = {67},
  number = {1},
  pages = {1--48},
  doi = {10.18637/jss.v067.i01},
}
@Article{R-lsmeans,
  title = {Least-Squares Means: The {R} Package {lsmeans}},
  author = {Russell V. Lenth},
  journal = {Journal of Statistical Software},
  year = {2016},
  volume = {69},
  number = {1},
  pages = {1--33},
  doi = {10.18637/jss.v069.i01},
}
@Manual{R-magrittr,
  title = {magrittr: A Forward-Pipe Operator for R},
  author = {Stefan Milton Bache and Hadley Wickham},
  year = {2014},
  note = {R package version 1.5},
  url = {https://CRAN.R-project.org/package=magrittr},
}
@Book{R-MASS,
  title = {Modern Applied Statistics with S},
  author = {W. N. Venables and B. D. Ripley},
  publisher = {Springer},
  edition = {Fourth},
  address = {New York},
  year = {2002},
  note = {ISBN 0-387-95457-0},
  url = {http://www.stats.ox.ac.uk/pub/MASS4},
}
@Manual{R-Matrix,
  title = {Matrix: Sparse and Dense Matrix Classes and Methods},
  author = {Douglas Bates and Martin Maechler},
  year = {2019},
  note = {R package version 1.2-17},
  url = {https://CRAN.R-project.org/package=Matrix},
}
@Manual{R-multcompView,
  title = {multcompView: Visualizations of Paired Comparisons},
  author = {Spencer Graves and Hans-Peter Piepho and Luciano Selzer with help from Sundar Dorai-Raj},
  year = {2015},
  note = {R package version 0.1-7},
  url = {https://CRAN.R-project.org/package=multcompView},
}
@Book{R-mvtnorm,
  title = {Computation of Multivariate Normal and t Probabilities},
  author = {Alan Genz and Frank Bretz},
  series = {Lecture Notes in Statistics},
  year = {2009},
  publisher = {Springer-Verlag},
  address = {Heidelberg},
  isbn = {978-3-642-01688-2},
}
@Manual{R-PairedData,
  title = {PairedData: Paired Data Analysis},
  author = {Stephane Champely},
  year = {2018},
  note = {R package version 1.1.1},
  url = {https://CRAN.R-project.org/package=PairedData},
}
@Manual{R-papaja,
  author = {Frederik Aust and Marius Barth},
  title = {{papaja}: {Create} {APA} manuscripts with {R Markdown}},
  year = {2018},
  note = {R package version 0.1.0.9842},
  url = {https://github.com/crsh/papaja},
}
@Manual{R-tidyr,
  title = {tidyr: Tidy Messy Data},
  author = {Hadley Wickham and Lionel Henry},
  year = {2019},
  note = {R package version 1.0.0},
  url = {https://CRAN.R-project.org/package=tidyr},
}
@Manual{R-magick,
  title = {magick: Advanced Graphics and Image-Processing in R},
  author = {Jeroen Ooms},
  year = {2020},
  note = {R package version 2.3},
  url = {https://CRAN.R-project.org/package=magick},
}
