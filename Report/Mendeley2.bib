@techreport{camerer1997experience,
author = {Camerer, Colin and Ho, Teck-Hua and Others},
title = {{Experience-weighted attraction learning in games: A unifying approach}},
year = {1997}
}
@article{cooper2003lessons,
author = {Cooper, David J and Kagel, John H},
journal = {American Economic Review},
number = {2},
pages = {202--207},
title = {{Lessons learned: generalizing learning across games}},
volume = {93},
year = {2003}
}
@article{Lake2017,
abstract = {Recent progress in artificial intelligence has renewed interest in building systems that learn and think like people. Many advances have come from using deep neural networks trained end-to-end in tasks such as object recognition, video games, and board games, achieving performance that equals or even beats that of humans in some respects. Despite their biological inspiration and performance achievements, these systems differ from human intelligence in crucial ways. We review progress in cognitive science suggesting that truly human-like learning and thinking machines will have to reach beyond current engineering trends in both what they learn and how they learn it. Specifically, we argue that these machines should (1) build causal models of the world that support explanation and understanding, rather than merely solving pattern recognition problems; (2) ground learning in intuitive theories of physics and psychology to support and enrich the knowledge that is learned; and (3) harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations. We suggest concrete challenges and promising routes toward these goals that can combine the strengths of recent neural network advances with more structured cognitive models.},
archivePrefix = {arXiv},
arxivId = {1604.00289},
author = {Lake, Brenden M. and Ullman, Tomer D. and Tenenbaum, Joshua B. and Gershman, Samuel J.},
doi = {10.1017/S0140525X16001837},
eprint = {1604.00289},
issn = {14691825},
journal = {Behavioral and Brain Sciences},
publisher = {Cambridge University Press},
title = {{Building machines that learn and think like people}},
volume = {40},
year = {2017}
}
@article{Woodruff,
author = {Woodruff, G and Sciences, D Premack - Behavioral and Brain and undefined 1978},
title = {{Does the chimpanzee have a theory of mind}}
}
@inproceedings{de2012higher,
author = {de Weerd, Harmen and Verbrugge, Rineke and Verheij, Bart},
booktitle = {Proceedings of the 11th International Conference on Autonomous Agents and Multiagent Systems-Volume 3},
pages = {1195--1196},
title = {{Higher-order social cognition in rock-paper-scissors: A simulation study}},
year = {2012}
}
@article{ho1998iterated,
author = {Ho, Teck-Hua and Camerer, Colin and Weigelt, Keith},
journal = {The American Economic Review},
number = {4},
pages = {947--969},
publisher = {JSTOR},
title = {{Iterated dominance and iterated best response in experimental" p-beauty contests"}},
volume = {88},
year = {1998}
}
@article{Haruvy2012,
abstract = {Rule learning posits that decision makers, rather than choosing over actions, choose over behavioral rules with different levels of sophistication. Rules are reinforced over time based on their historically observed payoffs in a given game. Past works on rule learning have shown that when playing a single game over a number of rounds, players can learn to form sophisticated beliefs about others. Here we are interested in learning that occurs between games where the set of actions is not directly comparable from one game to the next. We study a sequence of ten thrice-played dissimilar games. Using experimental data, we find that our rule learning model captures the ability of players to learn to reason across games. However, this learning appears different from within-game rule learning as previously documented. The main adjustment in sophistication occurs by switching from non-belief-based strategies to belief-based strategies. The sophistication of the beliefs themselves increases only slightly over time. {\textcopyright} 2011 Elsevier Inc.},
author = {Haruvy, Ernan and Stahl, Dale O.},
doi = {10.1016/j.geb.2011.06.001},
file = {:Users/mbp17/Library/Application Support/Mendeley Desktop/Downloaded/Haruvy, Stahl - 2012 - Between-game rule learning in dissimilar symmetric normal-form games.pdf:pdf},
issn = {08998256},
journal = {Games and Economic Behavior},
keywords = {Experiments,Learning,Transference},
number = {1},
pages = {208--221},
publisher = {Elsevier Inc.},
title = {{Between-game rule learning in dissimilar symmetric normal-form games}},
url = {http://dx.doi.org/10.1016/j.geb.2011.06.001},
volume = {74},
year = {2012}
}
@article{arad201211,
author = {Arad, Ayala and Rubinstein, Ariel},
journal = {American Economic Review},
number = {7},
pages = {3561--3573},
title = {{The 11-20 money request game: A level-k reasoning study}},
volume = {102},
year = {2012}
}
@incollection{mertens1990repeated,
author = {Mertens, Jean-Fran{\c{c}}ois},
booktitle = {Game Theory and Applications},
pages = {77--130},
publisher = {Elsevier},
title = {{Repeated games}},
year = {1990}
}
@article{Stahl2008,
author = {Stahl, Dale O},
file = {:Users/mbp17/Library/Application Support/Mendeley Desktop/Downloaded/Stahl - 2008 - Learning Transference Between Dissimilar Symmetric Normal-Form Games.pdf:pdf},
keywords = {experiments,learning,transference},
title = {{Learning Transference Between Dissimilar Symmetric Normal-Form Games}},
year = {2008}
}
@article{shachat2004we,
author = {Shachat, Jason and Swarthout, J Todd},
journal = {Mathematical Methods of Operations Research},
number = {3},
pages = {359--373},
publisher = {Springer},
title = {{Do we detect and exploit mixed strategy play by opponents?}},
volume = {59},
year = {2004}
}
@techreport{Camerer,
abstract = {Coordination games have multiple Nash equilibria (i.e., sets of strategies which are best responses to one another). In``In``weak-link" coordination games players choose a number 1-7. Their payoff is increasing in the minimum number (or weakest link) and decreasing in the difference between their number and the minimum. Choosing 7 is an``an``efficient" equilibrium because it gives everybody a higher payoff than any other coordinated choice. Higher-payoff equilibria are riskier, however, so the game expresses the tradeoff between group efficiency and personal risk present in many social and organizational settings. We tested whether choosing efficiently in a weak-link game increases cooperative play in a subsequent prisoner's dilemma (PD) game. This cross-game transfer resembles transfer of cooperative norms in small firms (which are more like coordination games than PDs) as firms grow larger and become like PDs. In two experiments, if a group of players share a history of playing the weak-link game efficiently, that efficiency precedent can transfer to a subsequent PD game, improving the level of cooperativeness. The effect of transfer is much larger in magnitude (increasing cooperation from 15-30{\%} to 71{\%}) than the effects of most variables in previous PD studies. However, the transfer effect depends on descriptive similarity of strategies in the two games, since it largely disappears when the strategies are numbered differently in the weak-link game and the PD.},
author = {Camerer, Colin and Knez, Marc},
file = {:Users/mbp17/Library/Application Support/Mendeley Desktop/Downloaded/Camerer, Knez - Unknown - Increasing Cooperation in Prisoner's Dilemmas by Establishing a Precedent of Efficiency in Coordination Games.pdf:pdf},
title = {{Increasing Cooperation in Prisoner's Dilemmas by Establishing a Precedent of Efficiency in Coordination Games}}
}
@article{Vickery2015,
abstract = {Context plays a pivotal role in many decision-making scenarios, including social interactions wherein the identities and strategies of other decision makers often shape our behaviors. However, the neural mechanisms for tracking such contextual information are poorly understood. Here, we investigated how opponent identity affects human reinforcement learning during a simulated competitive game against two independent computerized opponents. We found that strategies of participants were affected preferentially by the outcomes of the previous interactions with the same opponent. In addition, reinforcement signals from the previous trial were less discriminable throughout the brain after the opponent changed, compared with when the same opponent was repeated. These opponent-selective reinforcement signals were particularly robust in right rostral anterior cingulate and right lingual regions, where opponent-selective reinforcement signals correlated with a behavioral measure of opponent-selective reinforcement learning. Therefore, when choices involve multiple contextual frames, such as different opponents in a game, decision making and its neural correlates are influenced by multithreaded histories of reinforcement. Overall, our findings are consistent with the availability of temporally overlapping, contextspecific reinforcement signals.},
author = {Vickery, Timothy J. and Kleinman, Matthew R. and Chun, Marvin M. and Lee, Daeyeol},
doi = {10.1523/JNEUROSCI.3530-14.2015},
file = {:Users/mbp17/Library/Application Support/Mendeley Desktop/Downloaded/Vickery et al. - 2015 - Opponent identity influences value learning in simple games.pdf:pdf},
issn = {15292401},
journal = {Journal of Neuroscience},
keywords = {Decision making,FMRI,Games,Reinforcement},
number = {31},
pages = {11133--11143},
title = {{Opponent identity influences value learning in simple games}},
volume = {35},
year = {2015}
}
@article{stahl1995players,
author = {Stahl, Dale O and Wilson, Paul W},
journal = {Games and Economic Behavior},
number = {1},
pages = {218--254},
publisher = {Elsevier},
title = {{On players models of other players: Theory and experimental evidence}},
volume = {10},
year = {1995}
}
@article{Rick2010,
abstract = {Psychologists have long recognized two kinds of learning: one that is relatively shallow and domain-specific; and another that is deeper, producing generalizable insights that transfer across domains. The game theory literature has only recently considered this distinction, and the conditions that stimulate the latter kind of "meaningful" learning in games are still unclear. Three experiments demonstrate that one kind of meaningful learning - acquisition of iterated dominance - occurs in the absence of any feedback. We demonstrate that such feedback-free meaningful learning transfers to new strategically similar games, and that such transfer does not typically occur when initial games are played with feedback. The effects of withholding feedback are similar to, and substitutable with, those produced by requiring players to explain their behavior, a method commonly employed in psychology to increase deliberation. This similarity suggests that withholding feedback encourages deeper thinking about the game in a manner similar to such self-explanation. {\textcopyright} 2009 Elsevier Inc. All rights reserved.},
author = {Rick, Scott and Weber, Roberto A.},
doi = {10.1016/j.geb.2009.10.004},
file = {:Users/mbp17/Library/Application Support/Mendeley Desktop/Downloaded/Rick, Weber - 2010 - Meaningful learning and transfer of learning in games played repeatedly without feedback.pdf:pdf},
issn = {08998256},
journal = {Games and Economic Behavior},
number = {2},
pages = {716--730},
publisher = {Elsevier Inc.},
title = {{Meaningful learning and transfer of learning in games played repeatedly without feedback}},
url = {http://dx.doi.org/10.1016/j.geb.2009.10.004},
volume = {68},
year = {2010}
}
@article{Ioannou2014,
abstract = {We propose a methodology that is generalizable to a broad class of repeated games in order to facilitate operability of belief-learning models with repeated-game strategies. The methodology consists of (1) a generalized repeated-game strategy space, (2) a mapping between histories and repeated-game beliefs, and (3) asynchronous updating of repeated-game strategies. We implement the proposed methodology by building on three proven action-learning models. Their predictions with repeated-game strategies are then validated with data from experiments with human subjects in four, symmetric 2 × 2 games: Prisoner's Dilemma, Battle of the Sexes, Stag-Hunt, and Chicken. The models with repeated-game strategies approximate subjects' behavior substantially better than their respective models with action learning. Additionally, inferred rules of behavior in the experimental data overlap with the predicted rules of behavior. {\textcopyright} 2014 Elsevier Inc.},
author = {Ioannou, Christos A. and Romero, Julian},
doi = {10.1016/j.geb.2014.05.007},
file = {:Users/mbp17/Library/Application Support/Mendeley Desktop/Downloaded/Ioannou, Romero - 2014 - A generalized approach to belief learning in repeated games.pdf:pdf},
issn = {10902473},
journal = {Games and Economic Behavior},
keywords = {Adaptive models,Battle of the Sexes,Belief learning,Chicken,Finite automata,Prisoner's Dilemma,Repeated-game strategies,Stag-Hunt},
pages = {178--203},
publisher = {Elsevier Inc.},
title = {{A generalized approach to belief learning in repeated games}},
url = {http://dx.doi.org/10.1016/j.geb.2014.05.007},
volume = {87},
year = {2014}
}
@article{ho2004economics,
author = {Ho, Teck H and Camerer, Colin F and Chong, Juin-Kuan},
publisher = {California Institute of Technology},
title = {{The economics of learning models: A self-tuning theory of learning in games}},
year = {2004}
}
@article{goodie2012levels,
author = {Goodie, Adam S and Doshi, Prashant and Young, Diana L},
journal = {Journal of Behavioral Decision Making},
number = {1},
pages = {95--108},
publisher = {Wiley Online Library},
title = {{Levels of theory-of-mind reasoning in competitive games}},
volume = {25},
year = {2012}
}
@article{simon1972theories,
author = {Simon, Herbert A},
journal = {Decision and organization},
number = {1},
pages = {161--176},
publisher = {North-Holland},
title = {{Theories of bounded rationality}},
volume = {1},
year = {1972}
}
@article{watkins1992q,
author = {Watkins, Christopher J C H and Dayan, Peter},
journal = {Machine learning},
number = {3-4},
pages = {279--292},
publisher = {Springer},
title = {{Q-learning}},
volume = {8},
year = {1992}
}
@article{Cooper2008,
abstract = {We explore how learning to play strategically in one signaling game promotes strategic play in a related signaling game. Following convergence to a pooling equilibrium, payoffs are changed to only support separating equilibria. More strategic play is observed following the change in payoffs than for inexperienced subjects in control sessions, contrary to the prediction of a fictitious play learning model. Introducing a growing proportion of sophisticated learners, subjects who anticipate responders' behavior following the change in payoffs, enables the model to capture the positive cross-game learning observed in the data. {\textcopyright} 2007 Springer-Verlag.},
author = {Cooper, David J. and Kagel, John H.},
doi = {10.1007/s00199-006-0192-5},
file = {:Users/mbp17/Library/Application Support/Mendeley Desktop/Downloaded/Cooper, Kagel - 2008 - Learning and transfer in signaling games.pdf:pdf},
isbn = {1216368503},
issn = {09382259},
journal = {Economic Theory},
keywords = {Cross-game learning,Experiment,Learning,Learning transfer,Signaling games},
number = {3},
pages = {415--439},
title = {{Learning and transfer in signaling games}},
volume = {34},
year = {2008}
}
@article{perkins1992transfer,
author = {Perkins, David N and Salomon, Gavriel and Others},
journal = {International encyclopedia of education},
pages = {6452--6457},
publisher = {Citeseer},
title = {{Transfer of learning}},
volume = {2},
year = {1992}
}
@book{cheung1994learning,
author = {Cheung, Yin-Wong and Friedman, Daniel},
publisher = {University of California, Santa Cruz},
title = {{Learning in evolutionary games: some laboratory results}},
year = {1994}
}
@article{baarslag2016learning,
author = {Baarslag, Tim and Hendrikx, Mark J C and Hindriks, Koen V and Jonker, Catholijn M},
journal = {Autonomous Agents and Multi-Agent Systems},
number = {5},
pages = {849--898},
publisher = {Springer},
title = {{Learning about the opponent in automated bilateral negotiation: a comprehensive survey of opponent modeling techniques}},
volume = {30},
year = {2016}
}
@article{spiliopoulos2013strategic,
author = {Spiliopoulos, Leonidas},
journal = {Autonomous agents and multi-agent systems},
number = {1},
pages = {131--160},
publisher = {Springer},
title = {{Strategic adaptation of humans playing computer algorithms in a repeated constant-sum game}},
volume = {27},
year = {2013}
}
@article{Juvina2015,
abstract = {We present a computational cognitive model that explains transfer of learning across two games of strategic interaction - Prisoner's Dilemma and Chicken. We summarize prior research showing that, when these games are played in sequence, the experience acquired in the first game influences the players' behavior in the second game. The same model accounts for human data in both games. The model explains transfer effects with the aid of a trust mechanism that determines how rewards change depending on the dynamics of the interaction between players. We conclude that factors pertaining to the game or the individual are insufficient to explain the whole range of transfer effects and factors pertaining to the interaction between players should be considered as well.},
author = {Juvina, Ion and Lebiere, Christian and Gonzalez, Cleotilde},
doi = {10.1016/j.jarmac.2014.09.004},
file = {:Users/mbp17/Library/Application Support/Mendeley Desktop/Downloaded/Juvina, Lebiere, Gonzalez - 2015 - Modeling trust dynamics in strategic interaction.pdf:pdf},
issn = {22113681},
journal = {Journal of Applied Research in Memory and Cognition},
keywords = {Cognitive modeling,Social dilemmas,Strategic interaction,Transfer of learning,Trust dynamics},
number = {3},
pages = {197--211},
publisher = {The Society for Applied Research in Memory and Cognition},
title = {{Modeling trust dynamics in strategic interaction}},
url = {http://dx.doi.org/10.1016/j.jarmac.2014.09.004},
volume = {4},
year = {2015}
}
@article{Kool_2011,
author = {{Wouter Kool, Joseph T. McGuire, Zev B. Rosen, Matthew M. Bovinick}},
doi = {10.2996/kmj/1138846322},
file = {:Users/mbp17/Downloads/nihms-213123.pdf:pdf},
issn = {03865991},
journal = {Experimental Psychology},
title = {{Decision Making and the Avoidance of Cognitive Demand}},
year = {2011}
}
@article{Simon_Daw_11,
abstract = {There is much evidence that humans and other animals utilize a combination of model-based and model-free RL methods. Although it has been proposed that these systems may dominate according to their relative statistical efficiency in different circumstances, there is little specific evidence - especially in humans - as to the details of this trade-off. Accordingly, we examine the relative performance of different RL approaches under situations in which the statistics of reward are differentially noisy and volatile. Using theory and simulation, we show that model-free TD learning is relatively most disadvantaged in cases of high volatility and low noise. We present data from a decision-making experiment manipulating these parameters, showing that humans shift learning strategies in accord with these predictions. The statistical circumstances favoring model-based RL are also those that promote a high learning rate, which helps explain why, in psychology, the distinction between these strategies is traditionally conceived in terms of rulebased vs. incremental learning.},
author = {Simon, Dylan A. and Daw, Nathaniel D.},
file = {:Users/mbp17/Downloads/4243-environmental-statistics-and-the-trade-off-between-model-based-and-td-learning-in-humans.pdf:pdf},
isbn = {9781618395993},
journal = {Advances in Neural Information Processing Systems 24: 25th Annual Conference on Neural Information Processing Systems 2011, NIPS 2011},
pages = {1--9},
title = {{Environmental statistics and the trade-off between model-based and TD learning in humans}},
year = {2011}
}
@article{Juvina2013,
abstract = {We studied transfer of learning across two games of strategic interaction. We found that the interpersonal relation between two players during and across two games influence development of reciprocal trust and transfer of learning from one game to another. We show that two types of similarities between the games affect transfer: (1) deep similarities facilitate transfer of an optimal solution across games; (2) surface similarities can either facilitate or hinder transfer depending on whether they lead players toward an optimal or sub-optimal solution in the target game. Learning an optimal solution in a context of interdependence between players is associated with development of reciprocal trust, which in turn mediates transfer of learning across games. The results can be used to inform the design of training exercises to develop strategic interaction skills. {\textcopyright} 2012 Elsevier Inc.},
author = {Juvina, Ion and Saleem, Muniba and Martin, Jolie M. and Gonzalez, Cleotilde and Lebiere, Christian},
doi = {10.1016/j.obhdp.2012.09.004},
file = {:Users/mbp17/Library/Application Support/Mendeley Desktop/Downloaded/Juvina et al. - 2013 - Reciprocal trust mediates deep transfer of learning between games of strategic interaction.pdf:pdf},
issn = {07495978},
journal = {Organizational Behavior and Human Decision Processes},
keywords = {Cooperation,Games of strategic interaction,Reciprocal trust,Surface and deep similarities,Transfer of learning},
number = {2},
pages = {206--215},
publisher = {Elsevier Inc.},
title = {{Reciprocal trust mediates deep transfer of learning between games of strategic interaction}},
url = {http://dx.doi.org/10.1016/j.obhdp.2012.09.004},
volume = {120},
year = {2013}
}
@Manual{R-afex,
  title = {afex: Analysis of Factorial Experiments},
  author = {Henrik Singmann and Ben Bolker and Jake Westfall and Frederik Aust and Mattan S. Ben-Shachar},
  year = {2020},
  note = {R package version 0.27-2},
  url = {https://CRAN.R-project.org/package=afex},
}
@Manual{R-base,
  title = {R: A Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  organization = {R Foundation for Statistical Computing},
  address = {Vienna, Austria},
  year = {2019},
  url = {https://www.R-project.org/},
}
@Book{R-bookdown,
  title = {bookdown: Authoring Books and Technical Documents with {R} Markdown},
  author = {Yihui Xie},
  publisher = {Chapman and Hall/CRC},
  address = {Boca Raton, Florida},
  year = {2016},
  note = {ISBN 978-1138700109},
  url = {https://github.com/rstudio/bookdown},
}
@Manual{R-citr,
  title = {citr: 'RStudio' Add-in to Insert Markdown Citations},
  author = {Frederik Aust},
  year = {2019},
  note = {R package version 0.3.2},
  url = {https://CRAN.R-project.org/package=citr},
}
@Article{R-depmixS4,
  title = {{depmixS4}: An {R} Package for Hidden Markov Models},
  author = {Ingmar Visser and Maarten Speekenbrink},
  journal = {Journal of Statistical Software},
  year = {2010},
  volume = {36},
  number = {7},
  pages = {1--21},
  url = {http://www.jstatsoft.org/v36/i07/},
}
@Manual{R-dplyr,
  title = {dplyr: A Grammar of Data Manipulation},
  author = {Hadley Wickham and Romain François and Lionel {
             Henry} and Kirill Müller},
  year = {2020},
  note = {R package version 1.0.2},
  url = {https://CRAN.R-project.org/package=dplyr},
}
@Manual{R-emmeans,
  title = {emmeans: Estimated Marginal Means, aka Least-Squares Means},
  author = {Russell Lenth},
  year = {2020},
  note = {R package version 1.5.0},
  url = {https://CRAN.R-project.org/package=emmeans},
}
@Book{R-ggplot2,
  author = {Hadley Wickham},
  title = {ggplot2: Elegant Graphics for Data Analysis},
  publisher = {Springer-Verlag New York},
  year = {2016},
  isbn = {978-3-319-24277-4},
  url = {https://ggplot2.tidyverse.org},
}
@Manual{R-ggpubr,
  title = {ggpubr: 'ggplot2' Based Publication Ready Plots},
  author = {Alboukadel Kassambara},
  year = {2020},
  note = {R package version 0.4.0},
  url = {https://CRAN.R-project.org/package=ggpubr},
}
@Manual{R-gld,
  title = {gld: Estimation and Use of the Generalised (Tukey) Lambda
Distribution},
  author = {Robert King and Benjamin Dean and Sigbert Klinke and Paul {van Staden}},
  year = {2020},
  note = {R package version 2.6.2},
  url = {https://CRAN.R-project.org/package=gld},
}
@Book{R-knitr,
  title = {Dynamic Documents with {R} and knitr},
  author = {Yihui Xie},
  publisher = {Chapman and Hall/CRC},
  address = {Boca Raton, Florida},
  year = {2015},
  edition = {2nd},
  note = {ISBN 978-1498716963},
  url = {https://yihui.org/knitr/},
}
@Book{R-lattice,
  title = {Lattice: Multivariate Data Visualization with R},
  author = {Deepayan Sarkar},
  publisher = {Springer},
  address = {New York},
  year = {2008},
  note = {ISBN 978-0-387-75968-5},
  url = {http://lmdvr.r-forge.r-project.org},
}
@Article{R-lme4,
  title = {Fitting Linear Mixed-Effects Models Using {lme4}},
  author = {Douglas Bates and Martin M{\"a}chler and Ben Bolker and Steve Walker},
  journal = {Journal of Statistical Software},
  year = {2015},
  volume = {67},
  number = {1},
  pages = {1--48},
  doi = {10.18637/jss.v067.i01},
}
@Article{R-lsmeans,
  title = {Least-Squares Means: The {R} Package {lsmeans}},
  author = {Russell V. Lenth},
  journal = {Journal of Statistical Software},
  year = {2016},
  volume = {69},
  number = {1},
  pages = {1--33},
  doi = {10.18637/jss.v069.i01},
}
@Manual{R-magick,
  title = {magick: Advanced Graphics and Image-Processing in R},
  author = {Jeroen Ooms},
  year = {2020},
  note = {R package version 2.4.0},
  url = {https://CRAN.R-project.org/package=magick},
}
@Book{R-MASS,
  title = {Modern Applied Statistics with S},
  author = {W. N. Venables and B. D. Ripley},
  publisher = {Springer},
  edition = {Fourth},
  address = {New York},
  year = {2002},
  note = {ISBN 0-387-95457-0},
  url = {http://www.stats.ox.ac.uk/pub/MASS4/},
}
@Manual{R-Matrix,
  title = {Matrix: Sparse and Dense Matrix Classes and Methods},
  author = {Douglas Bates and Martin Maechler},
  year = {2019},
  note = {R package version 1.2-18},
  url = {https://CRAN.R-project.org/package=Matrix},
}
@Manual{R-multcompView,
  title = {multcompView: Visualizations of Paired Comparisons},
  author = {Spencer Graves and Hans-Peter Piepho and Luciano Selzer with help from Sundar Dorai-Raj},
  year = {2019},
  note = {R package version 0.1-8},
  url = {https://CRAN.R-project.org/package=multcompView},
}
@Book{R-mvtnorm,
  title = {Computation of Multivariate Normal and t Probabilities},
  author = {Alan Genz and Frank Bretz},
  series = {Lecture Notes in Statistics},
  year = {2009},
  publisher = {Springer-Verlag},
  address = {Heidelberg},
  isbn = {978-3-642-01688-2},
}
@Manual{R-nlme,
  title = {{nlme}: Linear and Nonlinear Mixed Effects Models},
  author = {Jose Pinheiro and Douglas Bates and Saikat DebRoy and Deepayan Sarkar and {R Core Team}},
  year = {2020},
  note = {R package version 3.1-149},
  url = {https://CRAN.R-project.org/package=nlme},
}
@Book{R-nnet,
  title = {Modern Applied Statistics with S},
  author = {W. N. Venables and B. D. Ripley},
  publisher = {Springer},
  edition = {Fourth},
  address = {New York},
  year = {2002},
  note = {ISBN 0-387-95457-0},
  url = {http://www.stats.ox.ac.uk/pub/MASS4},
}
@Manual{R-PairedData,
  title = {PairedData: Paired Data Analysis},
  author = {Stephane Champely},
  year = {2018},
  note = {R package version 1.1.1},
  url = {https://CRAN.R-project.org/package=PairedData},
}
@Manual{R-papaja,
  author = {Frederik Aust and Marius Barth},
  title = {{papaja}: {Create} {APA} manuscripts with {R Markdown}},
  year = {2018},
  note = {R package version 0.1.0.9842},
  url = {https://github.com/crsh/papaja},
}
@Manual{R-Rsolnp,
  title = {Rsolnp: General Non-linear Optimization Using Augmented
    Lagrange Multiplier Method},
  author = {Alexios Ghalanos and Stefan Theussl},
  year = {2015},
  note = {R package version 1.16.},
}
@Manual{R-tidyr,
  title = {tidyr: Tidy Messy Data},
  author = {Hadley Wickham},
  year = {2020},
  note = {R package version 1.1.2},
  url = {https://CRAN.R-project.org/package=tidyr},
}
