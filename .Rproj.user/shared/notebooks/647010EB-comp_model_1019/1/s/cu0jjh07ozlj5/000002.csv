"0","naive_bayes <- function(par,data,opp_strategy_vec,return_value=c(""-2loglik"",""likelihood_by_trial"")) {"
"0","  # par = parameter, noise in computer choice"
"0","  # dat = data subset for one participant"
"0","  # opp_strategy_vec = c(""level0"",""level1"",""level2"")"
"0","  # return = -2logLik "
"0","  # or ""likelihood_by_trial"" vector  (for later plotting, etc)"
"0","  "
"0","  return_value <- match.arg(return_value)"
"0","  theta <- par[1]"
"0","  eps <- par[2]"
"0","  "
"0","  num_strat = length(opp_strategy_vec) "
"0","  # set up a vector to store the likelihood"
"0","  lik_opp <- matrix(0.0,num_strat, nrow(data))"
"0","  lik_hum <- matrix(0.0,nrow(data))"
"0","  br_hum <- rep(NA,num_strat)"
"0","  # Initiate prior vector as uniform"
"0","  opp_prior_vec <-rep(1/num_strat, num_strat)"
"0","  "
"0","  for(t in 1:nrow(data)) {"
"0","    t_game <- data[t,""game""]"
"0","    pred_file_opp <- switch(as.character(t_game),rps = rps_predict_opp,fwg = fwg_predict_opp, numbers = numbers_predict_opp)"
"0","    if(t_game == ""numbers"") nopts <- 5 else nopts <- 3"
"0","    if(data[t,""round""] == 1) {"
"0","      # first round is uniform prediction"
"0","      pred <- NA"
"0","      lik_opp[,t] <- opp_prior_vec"
"0","      lik_hum[t] <- 1/nopts "
"0","    } else {"
"0","      # get prediction of opponent action from CSV files"
"0","      for (strategy in opp_strategy_vec) {"
"0","        k = match(strategy,opp_strategy_vec)"
"0","        pred_opp <- as.character(filter(pred_file_opp,human_previous == as.character(data[t-1,""h_action""]) & computer_previous == as.character(data[t-1,""a_action""]))[strategy][1,])"
"0","        # Given opponent action predicted, what would be human action best response for each opp strat"
"0","        br_hum[[k]] <- best_response(t_game,as.character(pred_opp))"
"0","        #cat(as.character(br_hum[[k]]), ""\n"")"
"0","        # Multiply prior by likelihood of observation to get posterior "
"0","        if(as.character(data[t,""a_action""]) == pred_opp) {"
"0","          lik_opp[k,t] <- (theta + (1-theta)/nopts)*opp_prior_vec[k]"
"0","        } else {"
"0","          lik_opp[k,t] <- ((1-theta)/nopts)*opp_prior_vec[k]"
"0","        }"
"0","      }"
"0","      # Get which opponent strategy human current actn maps to (if index = 0 then human current action is br to level-0 comp_strat...)"
"0","      # NOTE!! -> ...assumes this is unique. check"
"0","      indices <- which(br_hum %in% as.character(data[t,""h_action""]))"
"0","      #cat(as.character(indices),  ""\n"")"
"0",""
"0","      # THEN likelihood of current human action is just prior on opponent vec (haven't updated priors with curr opp act yet)"
"0","      # if action is not predicted by any level-k OM, assume human chooses randomly with prob eps"
"0","      if(length(indices) == 0){"
"0","        lik_hum[t] <- eps/nopts"
"0","      # if same br action for multiple possible ai opponents, add probabilities "
"0","      } else {"
"0","        lik_hum[t] <- sum(opp_prior_vec[indices])*(1-eps) + eps/nopts"
"0","      }"
"0","      # Standardising the probabilities and updating prior"
"0","      lik_opp[,t] <- lik_opp[,t]/sum(lik_opp[,t])"
"0","      opp_prior_vec <- lik_opp[,t]"
"0","    }"
"0","    # for debugging uncomment the line below"
"0","    #cat(as.character(pred_opp),as.character(data[t,""h_action""]),lik[,t],""\n"")"
"0","  }"
"0","  if(return_value == ""-2loglik"") {"
"0","    ret <- -2*sum(log(lik_hum))"
"0","    if(is.infinite(ret)) {"
"0","      return(1e+300)"
"0","    } else {"
"0","      return(ret)"
"0","    }"
"0","  }"
"0","  if(return_value == ""likelihood_by_trial"") return(lik_hum)"
"0","}"
"0",""
