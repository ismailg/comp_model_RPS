pred_file_opp <- switch(as.character(t_game),rps = rps_predict_opp,fwg = fwg_predict_opp, numbers = numbers_predict_opp)
if(t_game == "numbers") nopts <- 5 else nopts <- 3
if(data[t,"round"] == 1) {
# first round is uniform prediction
pred_opp <- NA
lik_hum[t] <- 1/nopts
if (!(opp_mod_transfer)) {
opp_prior_vec <- rep(1/num_strat, num_strat)
lik_opp[,t] <- opp_prior_vec
}
# Rounds after first
} else {
# get prediction of opponent action from CSV files
for (strategy in opp_strategy_vec) {
k = match(strategy,opp_strategy_vec)
pred_opp <- as.character(filter(pred_file_opp, pred_file_opp$human_previous == as.character(data[t-1,"h_action"]) & pred_file_opp$computer_previous == as.character(data[t-1,"a_action"]))[[k]])
# Given opponent action predicted, what would be human action best response for each opp strat
br_hum[[k]] <- best_response(t_game,as.character(pred_opp))
# Multiply prior by likelihood of observation to get posterior. Done here ot take advantage of For loop.
if(as.character(data[t,"a_action"]) == pred_opp) {
lik_opp[k,t] <- (theta + (1-theta)/nopts)*opp_prior_vec[k]
} else {
lik_opp[k,t] <- ((1-theta)/nopts)*opp_prior_vec[k]
}
}
# Get which opponent strategy human current actn maps to (if index = 0 then human current action is br to level-0 comp_strat...)
indices <- which(br_hum %in% as.character(data[t,"h_action"]))
# THEN likelihood of current human action is just prior on opponent vec (haven't updated priors with curr opp act yet)
# if action is not predicted by any level-k OM, assume human chooses randomly with prob eps
if(length(indices) == 0){
lik_hum[t] <- eps/nopts
# if same br action for multiple possible ai opponents, add probabilities
} else {
lik_hum[t] <- sum(opp_prior_vec[indices])*(1-eps) + eps/nopts
}
# Standardising the probabilities and updating prior
lik_opp[,t] <- lik_opp[,t]/sum(lik_opp[,t])
opp_prior_vec <- lik_opp[,t]
}
# for debugging uncomment the line below
#cat(as.character(pred_opp),as.character(data[t,"h_action"]),lik[,t],"\n")
}
if(return_value == "-2loglik") {
ret <- -2*sum(log(lik_hum))
if(is.infinite(ret) || is.nan(ret)) {
return(1e+300)
} else {
return(ret)
}
}
#if(return_value == "likelihood_by_trial") return(lik_hum)
}
# Fitting a bayesiam model WITH TRANSFER of opp strat distribution between games
TR_bayes_modelling <- list()
for(id in unique(dat$human_id)) {
cat("new_id")
TR_bayes_modelling[[id]] <- list()
tdat <- subset(dat,human_id == id)
TR_bayes_modelling[[id]] <- DEoptim(fn=naive_bayes, lower = c(0.0,0.0), upper = c(1.0,1.0), data=tdat, opp_strategy_vec = c("level0","level1","level2"),return_value = "-2loglik", opp_mod_transfer = TRUE, control=list(trace = FALSE, parallelType=1,parVar = c("best_response")))
# TR_bayes_modelling[[id]] <- optim(c(0.1,0.1),fn=naive_bayes,gr = NULL, data=tdat,opp_strategy_vec = c("level0","level1","level2"),return_value = "-2loglik", opp_mod_transfer = TRUE,lower = c(0.01,0.01), upper = c(0.99,0.99), method="L-BFGS-B")
}
# Function to produce best reponse to ai_action
best_response <- function(game,ai_action){
if (game == "rps"){
if (ai_action == "R") {return("P")}
else if (ai_action == "P") {return("S")}
else if (ai_action == "S") {return("R")}
} else if (game == "fwg"){
if (ai_action == "F") {return("W")}
else if (ai_action == "W") {return("G")}
else if (ai_action == "G") {return("F")}
} else if (game == "numbers") {
if (ai_action == "1") {return("2")}
else if (ai_action == "2") {return("3")}
else if (ai_action == "3") {return("4")}
else if (ai_action == "4") {return("5")}
else if (ai_action == "5") {return("1")}
}
}
naive_bayes <- function(par,data,opp_strategy_vec,return_value,opp_mod_transfer) {
# theta = parameter, probability computer will play its best response to what it thinks human is. Truth = 90%. in [0,1].
# Epsilone: parameter controlling noise in human choice. Probability human will deviate from its best response. In [0,1].
# dat = data subset for one participant
# opp_strategy_vec = vector of possible opponent strtegies, model assumes humans restrict opp strategy space to vector   c("level0","level1","level2")
# return = -2logLik
# or "likelihood_by_trial" vector  (for later plotting, etc)
# opp_mod_transfer is a boolean. True if distribution of opponent strategies is kept across games. False otherwise.
#return_value <- match.arg(return_value)
theta <- par[1]
eps <- par[2]
num_strat = length(opp_strategy_vec)
# Load tables predicting oppponent move
rps_predict_opp <- read.csv("rps_predict_opp.csv")
fwg_predict_opp <- read.csv("fwg_predict_opp.csv")
numbers_predict_opp <- read.csv("numbers_predict_opp.csv")
#lik_opp is a vector that holds and update probability distribution of opp strategy given actions.
lik_opp <- matrix(0.0,num_strat, nrow(data))
# Initiate prior vector as uniform
opp_prior_vec <-rep(1/num_strat, num_strat)
lik_hum <- matrix(0.0,nrow(data))
# br_hum is vector that stores best responses of human to actions taken by each level-k ai opponent at the round.
br_hum <- rep(NA,num_strat)
for(t in 1:nrow(data)) {
t_game <- data[t,"game"]
pred_file_opp <- switch(as.character(t_game),rps = rps_predict_opp,fwg = fwg_predict_opp, numbers = numbers_predict_opp)
if(t_game == "numbers") nopts <- 5 else nopts <- 3
if(data[t,"round"] == 1) {
# first round is uniform prediction
pred_opp <- NA
lik_hum[t] <- 1/nopts
if (!(opp_mod_transfer)) {
opp_prior_vec <- rep(1/num_strat, num_strat)
lik_opp[,t] <- opp_prior_vec
}
# Rounds after first
} else {
# get prediction of opponent action from CSV files
for (strategy in opp_strategy_vec) {
k = match(strategy,opp_strategy_vec)
pred_opp <- as.character(filter(pred_file_opp, pred_file_opp$human_previous == as.character(data[t-1,"h_action"]) & pred_file_opp$computer_previous == as.character(data[t-1,"a_action"]))[[k]])
# Given opponent action predicted, what would be human action best response for each opp strat
br_hum[[k]] <- best_response(t_game,as.character(pred_opp))
# Multiply prior by likelihood of observation to get posterior. Done here ot take advantage of For loop.
if(as.character(data[t,"a_action"]) == pred_opp) {
lik_opp[k,t] <- (theta + (1-theta)/nopts)*opp_prior_vec[k]
} else {
lik_opp[k,t] <- ((1-theta)/nopts)*opp_prior_vec[k]
}
}
# Get which opponent strategy human current actn maps to (if index = 0 then human current action is br to level-0 comp_strat...)
indices <- which(br_hum %in% as.character(data[t,"h_action"]))
# THEN likelihood of current human action is just prior on opponent vec (haven't updated priors with curr opp act yet)
# if action is not predicted by any level-k OM, assume human chooses randomly with prob eps
if(length(indices) == 0){
lik_hum[t] <- eps/nopts
# if same br action for multiple possible ai opponents, add probabilities
} else {
lik_hum[t] <- sum(opp_prior_vec[indices])*(1-eps) + eps/nopts
}
# Standardising the probabilities and updating prior
lik_opp[,t] <- lik_opp[,t]/sum(lik_opp[,t])
opp_prior_vec <- lik_opp[,t]
}
# for debugging uncomment the line below
#cat(as.character(pred_opp),as.character(data[t,"h_action"]),lik[,t],"\n")
}
if(return_value == "-2loglik") {
ret <- -2*sum(log(lik_hum))
if(is.infinite(ret) || is.nan(ret)) {
return(1e+300)
} else {
return(ret)
}
}
#if(return_value == "likelihood_by_trial") return(lik_hum)
}
data = subset(dat,human_id == "38VxtUSv_h6RR5-tAAA2")
naive_bayes(c(0.5,0.5),data,c("level0","level1","level2"),"-2loglik",TRUE)
warnings()
# Function to produce best reponse to ai_action
best_response <- function(game,ai_action){
if (game == "rps"){
if (ai_action == "R") {return("P")}
else if (ai_action == "P") {return("S")}
else if (ai_action == "S") {return("R")}
} else if (game == "fwg"){
if (ai_action == "F") {return("W")}
else if (ai_action == "W") {return("G")}
else if (ai_action == "G") {return("F")}
} else if (game == "numbers") {
if (ai_action == "1") {return("2")}
else if (ai_action == "2") {return("3")}
else if (ai_action == "3") {return("4")}
else if (ai_action == "4") {return("5")}
else if (ai_action == "5") {return("1")}
}
}
naive_bayes <- function(par,data,opp_strategy_vec,return_value,opp_mod_transfer) {
# theta = parameter, probability computer will play its best response to what it thinks human is. Truth = 90%. in [0,1].
# Epsilone: parameter controlling noise in human choice. Probability human will deviate from its best response. In [0,1].
# dat = data subset for one participant
# opp_strategy_vec = vector of possible opponent strtegies, model assumes humans restrict opp strategy space to vector   c("level0","level1","level2")
# return = -2logLik
# or "likelihood_by_trial" vector  (for later plotting, etc)
# opp_mod_transfer is a boolean. True if distribution of opponent strategies is kept across games. False otherwise.
#return_value <- match.arg(return_value)
theta <- par[1]
eps <- par[2]
num_strat = length(opp_strategy_vec)
# Load tables predicting oppponent move
rps_predict_opp <- read.csv("rps_predict_opp.csv")
fwg_predict_opp <- read.csv("fwg_predict_opp.csv")
numbers_predict_opp <- read.csv("numbers_predict_opp.csv")
#lik_opp is a vector that holds and update probability distribution of opp strategy given actions.
lik_opp <- matrix(0.0,num_strat, nrow(data))
# Initiate prior vector as uniform
opp_prior_vec <-rep(1/num_strat, num_strat)
lik_hum <- matrix(0.0,nrow(data))
# br_hum is vector that stores best responses of human to actions taken by each level-k ai opponent at the round.
br_hum <- rep(NA,num_strat)
for(t in 1:nrow(data)) {
t_game <- data[t,"game"]
pred_file_opp <- switch(as.character(t_game),rps = rps_predict_opp,fwg = fwg_predict_opp, numbers = numbers_predict_opp)
if(t_game == "numbers") nopts <- 5 else nopts <- 3
if(data[t,"round"] == 1) {
# first round is uniform prediction
pred_opp <- NA
lik_hum[t] <- 1/nopts
if (!(opp_mod_transfer)) {
opp_prior_vec <- rep(1/num_strat, num_strat)
lik_opp[,t] <- opp_prior_vec
}
# Rounds after first
} else {
# get prediction of opponent action from CSV files
for (strategy in opp_strategy_vec) {
k = match(strategy,opp_strategy_vec)
pred_opp <- as.character(filter(pred_file_opp, pred_file_opp$human_previous == as.character(data[t-1,"h_action"]) & pred_file_opp$computer_previous == as.character(data[t-1,"a_action"]))[[k]])
# Given opponent action predicted, what would be human action best response for each opp strat
br_hum[[k]] <- best_response(t_game,as.character(pred_opp))
# Multiply prior by likelihood of observation to get posterior. Done here ot take advantage of For loop.
if(as.character(data[t,"a_action"]) == pred_opp) {
lik_opp[k,t] <- (theta + (1-theta)/nopts)*opp_prior_vec[k]
} else {
lik_opp[k,t] <- ((1-theta)/nopts)*opp_prior_vec[k]
}
}
# Get which opponent strategy human current actn maps to (if index = 0 then human current action is br to level-0 comp_strat...)
indices <- which(br_hum %in% as.character(data[t,"h_action"]))
# THEN likelihood of current human action is just prior on opponent vec (haven't updated priors with curr opp act yet)
# if action is not predicted by any level-k OM, assume human chooses randomly with prob eps
if(length(indices) == 0){
lik_hum[t] <- eps/nopts
# if same br action for multiple possible ai opponents, add probabilities
} else {
lik_hum[t] <- sum(opp_prior_vec[indices])*(1-eps) + eps/nopts
}
# Standardising the probabilities and updating prior
lik_opp[,t] <- lik_opp[,t]/sum(lik_opp[,t])
opp_prior_vec <- lik_opp[,t]
}
# for debugging uncomment the line below
#cat(as.character(pred_opp),as.character(data[t,"h_action"]),lik[,t],"\n")
}
if(return_value == "-2loglik") {
ret <- -2*sum(log(lik_hum))
if(is.infinite(ret) || is.nan(ret)) {
return(1e+300)
} else {
return(ret)
}
}
#if(return_value == "likelihood_by_trial") return(lik_hum)
}
data = subset(dat,human_id == "38VxtUSv_h6RR5-tAAA2")
naive_bayes(c(0.01,0.99),data,c("level0","level1","level2"),"-2loglik",TRUE)
# Function to produce best reponse to ai_action
best_response <- function(game,ai_action){
if (game == "rps"){
if (ai_action == "R") {return("P")}
else if (ai_action == "P") {return("S")}
else if (ai_action == "S") {return("R")}
} else if (game == "fwg"){
if (ai_action == "F") {return("W")}
else if (ai_action == "W") {return("G")}
else if (ai_action == "G") {return("F")}
} else if (game == "numbers") {
if (ai_action == "1") {return("2")}
else if (ai_action == "2") {return("3")}
else if (ai_action == "3") {return("4")}
else if (ai_action == "4") {return("5")}
else if (ai_action == "5") {return("1")}
}
}
naive_bayes <- function(par,data,opp_strategy_vec,return_value,opp_mod_transfer) {
# theta = parameter, probability computer will play its best response to what it thinks human is. Truth = 90%. in [0,1].
# Epsilone: parameter controlling noise in human choice. Probability human will deviate from its best response. In [0,1].
# dat = data subset for one participant
# opp_strategy_vec = vector of possible opponent strtegies, model assumes humans restrict opp strategy space to vector   c("level0","level1","level2")
# return = -2logLik
# or "likelihood_by_trial" vector  (for later plotting, etc)
# opp_mod_transfer is a boolean. True if distribution of opponent strategies is kept across games. False otherwise.
#return_value <- match.arg(return_value)
theta <- par[1]
eps <- par[2]
num_strat = length(opp_strategy_vec)
# Load tables predicting oppponent move
rps_predict_opp <- read.csv("rps_predict_opp.csv")
fwg_predict_opp <- read.csv("fwg_predict_opp.csv")
numbers_predict_opp <- read.csv("numbers_predict_opp.csv")
#lik_opp is a vector that holds and update probability distribution of opp strategy given actions.
lik_opp <- matrix(0.0,num_strat, nrow(data))
# Initiate prior vector as uniform
opp_prior_vec <-rep(1/num_strat, num_strat)
lik_hum <- matrix(0.0,nrow(data))
# br_hum is vector that stores best responses of human to actions taken by each level-k ai opponent at the round.
br_hum <- rep(NA,num_strat)
for(t in 1:nrow(data)) {
t_game <- data[t,"game"]
pred_file_opp <- switch(as.character(t_game),rps = rps_predict_opp,fwg = fwg_predict_opp, numbers = numbers_predict_opp)
if(t_game == "numbers") nopts <- 5 else nopts <- 3
if(data[t,"round"] == 1) {
# first round is uniform prediction
pred_opp <- NA
lik_hum[t] <- 1/nopts
if (!(opp_mod_transfer)) {
opp_prior_vec <- rep(1/num_strat, num_strat)
lik_opp[,t] <- opp_prior_vec
}
# Rounds after first
} else {
# get prediction of opponent action from CSV files
for (strategy in opp_strategy_vec) {
k = match(strategy,opp_strategy_vec)
pred_opp <- as.character(filter(pred_file_opp, pred_file_opp$human_previous == as.character(data[t-1,"h_action"]) & pred_file_opp$computer_previous == as.character(data[t-1,"a_action"]))[[k]])
# Given opponent action predicted, what would be human action best response for each opp strat
br_hum[[k]] <- best_response(t_game,as.character(pred_opp))
# Multiply prior by likelihood of observation to get posterior. Done here ot take advantage of For loop.
if(as.character(data[t,"a_action"]) == pred_opp) {
lik_opp[k,t] <- (theta + (1-theta)/nopts)*opp_prior_vec[k]
} else {
lik_opp[k,t] <- ((1-theta)/nopts)*opp_prior_vec[k]
}
}
# Get which opponent strategy human current actn maps to (if index = 0 then human current action is br to level-0 comp_strat...)
indices <- which(br_hum %in% as.character(data[t,"h_action"]))
# THEN likelihood of current human action is just prior on opponent vec (haven't updated priors with curr opp act yet)
# if action is not predicted by any level-k OM, assume human chooses randomly with prob eps
if(length(indices) == 0){
lik_hum[t] <- eps/nopts
# if same br action for multiple possible ai opponents, add probabilities
} else {
lik_hum[t] <- sum(opp_prior_vec[indices])*(1-eps) + eps/nopts
}
# Standardising the probabilities and updating prior
lik_opp[,t] <- lik_opp[,t]/sum(lik_opp[,t])
opp_prior_vec <- lik_opp[,t]
}
# for debugging uncomment the line below
#cat(as.character(pred_opp),as.character(data[t,"h_action"]),lik[,t],"\n")
}
if(return_value == "-2loglik") {
ret <- -2*sum(log(lik_hum))
if(is.infinite(ret) || is.nan(ret)) {
return(1e+300)
} else {
return(ret)
}
}
#if(return_value == "likelihood_by_trial") return(lik_hum)
}
data = subset(dat,human_id == "38VxtUSv_h6RR5-tAAA2")
naive_bayes(c(0.01,0.99),data,c("level0","level1","level2"),"-2loglik",FALSE)
# Function to produce best reponse to ai_action
best_response <- function(game,ai_action){
if (game == "rps"){
if (ai_action == "R") {return("P")}
else if (ai_action == "P") {return("S")}
else if (ai_action == "S") {return("R")}
} else if (game == "fwg"){
if (ai_action == "F") {return("W")}
else if (ai_action == "W") {return("G")}
else if (ai_action == "G") {return("F")}
} else if (game == "numbers") {
if (ai_action == "1") {return("2")}
else if (ai_action == "2") {return("3")}
else if (ai_action == "3") {return("4")}
else if (ai_action == "4") {return("5")}
else if (ai_action == "5") {return("1")}
}
}
naive_bayes <- function(par,data,opp_strategy_vec,return_value,opp_mod_transfer) {
# theta = parameter, probability computer will play its best response to what it thinks human is. Truth = 90%. in [0,1].
# Epsilone: parameter controlling noise in human choice. Probability human will deviate from its best response. In [0,1].
# dat = data subset for one participant
# opp_strategy_vec = vector of possible opponent strtegies, model assumes humans restrict opp strategy space to vector   c("level0","level1","level2")
# return = -2logLik
# or "likelihood_by_trial" vector  (for later plotting, etc)
# opp_mod_transfer is a boolean. True if distribution of opponent strategies is kept across games. False otherwise.
#return_value <- match.arg(return_value)
theta <- par[1]
eps <- par[2]
num_strat = length(opp_strategy_vec)
# Load tables predicting oppponent move
rps_predict_opp <- read.csv("rps_predict_opp.csv")
fwg_predict_opp <- read.csv("fwg_predict_opp.csv")
numbers_predict_opp <- read.csv("numbers_predict_opp.csv")
#lik_opp is a vector that holds and update probability distribution of opp strategy given actions.
lik_opp <- matrix(0.0,num_strat, nrow(data))
# Initiate prior vector as uniform
opp_prior_vec <-rep(1/num_strat, num_strat)
lik_hum <- matrix(0.0,nrow(data))
# br_hum is vector that stores best responses of human to actions taken by each level-k ai opponent at the round.
br_hum <- rep(NA,num_strat)
for(t in 1:nrow(data)) {
t_game <- data[t,"game"]
pred_file_opp <- switch(as.character(t_game),rps = rps_predict_opp,fwg = fwg_predict_opp, numbers = numbers_predict_opp)
if(t_game == "numbers") nopts <- 5 else nopts <- 3
if(data[t,"round"] == 1) {
# first round is uniform prediction
pred_opp <- NA
lik_hum[t] <- 1/nopts
if (!(opp_mod_transfer)) {
opp_prior_vec <- rep(1/num_strat, num_strat)
lik_opp[,t] <- opp_prior_vec
}
# Rounds after first
} else {
# get prediction of opponent action from CSV files
for (strategy in opp_strategy_vec) {
k = match(strategy,opp_strategy_vec)
pred_opp <- as.character(filter(pred_file_opp, pred_file_opp$human_previous == as.character(data[t-1,"h_action"]) & pred_file_opp$computer_previous == as.character(data[t-1,"a_action"]))[[k]])
# Given opponent action predicted, what would be human action best response for each opp strat
br_hum[[k]] <- best_response(t_game,as.character(pred_opp))
# Multiply prior by likelihood of observation to get posterior. Done here ot take advantage of For loop.
if(as.character(data[t,"a_action"]) == pred_opp) {
lik_opp[k,t] <- (theta + (1-theta)/nopts)*opp_prior_vec[k]
} else {
lik_opp[k,t] <- ((1-theta)/nopts)*opp_prior_vec[k]
}
}
# Get which opponent strategy human current actn maps to (if index = 0 then human current action is br to level-0 comp_strat...)
indices <- which(br_hum %in% as.character(data[t,"h_action"]))
# THEN likelihood of current human action is just prior on opponent vec (haven't updated priors with curr opp act yet)
# if action is not predicted by any level-k OM, assume human chooses randomly with prob eps
if(length(indices) == 0){
lik_hum[t] <- eps/nopts
# if same br action for multiple possible ai opponents, add probabilities
} else {
lik_hum[t] <- sum(opp_prior_vec[indices])*(1-eps) + eps/nopts
}
# Standardising the probabilities and updating prior
lik_opp[,t] <- lik_opp[,t]/sum(lik_opp[,t])
opp_prior_vec <- lik_opp[,t]
}
# for debugging uncomment the line below
#cat(as.character(pred_opp),as.character(data[t,"h_action"]),lik[,t],"\n")
}
if(return_value == "-2loglik") {
ret <- -2*sum(log(lik_hum))
if(is.infinite(ret) || is.nan(ret)) {
return(1e+300)
} else {
return(ret)
}
}
#if(return_value == "likelihood_by_trial") return(lik_hum)
}
data = subset(dat,human_id == "38VxtUSv_h6RR5-tAAA2")
naive_bayes(c(0.01,0.99),data,c("level0","level1","level2"),"-2loglik",FALSE)
# Fitting a bayesiam model WITH TRANSFER of opp strat distribution between games
TR_bayes_modelling <- list()
for(id in unique(dat$human_id)) {
cat("new_id")
TR_bayes_modelling[[id]] <- list()
tdat <- subset(dat,human_id == id)
TR_bayes_modelling[[id]] <- DEoptim(fn=naive_bayes, lower = c(0.0,0.0), upper = c(1.0,1.0), data=tdat, opp_strategy_vec = ,return_value = "-2loglik", opp_mod_transfer = TRUE, control=list(trace = FALSE, parallelType=1,parVar = c("best_response")))
# TR_bayes_modelling[[id]] <- optim(c(0.1,0.1),fn=naive_bayes,gr = NULL, data=tdat,opp_strategy_vec = c("level0","level1","level2"),return_value = "-2loglik", opp_mod_transfer = TRUE,lower = c(0.01,0.01), upper = c(0.99,0.99), method="L-BFGS-B")
}
# Fitting a bayesiam model WITH TRANSFER of opp strat distribution between games
TR_bayes_modelling <- list()
for(id in unique(dat$human_id)) {
cat("new_id")
TR_bayes_modelling[[id]] <- list()
tdat <- subset(dat,human_id == id)
TR_bayes_modelling[[id]] <- DEoptim(fn=naive_bayes, lower = c(0.0,0.0), upper = c(1.0,1.0), data=tdat, opp_strategy_vec = c("level0","level1","level2") ,return_value = "-2loglik", opp_mod_transfer = TRUE, control=list(trace = FALSE, parallelType=1,parVar = c("best_response")))
TR_bayes_modelling[[id]] <- optim(c(0.1,0.1),fn=naive_bayes,gr = NULL, data=tdat,opp_strategy_vec = c("level0","level1","level2"),return_value = "-2loglik", opp_mod_transfer = TRUE,lower = c(0.01,0.01), upper = c(0.99,0.99), method="L-BFGS-B")
}
# Fitting a bayesiam model WITH TRANSFER of opp strat distribution between games
TR_bayes_modelling <- list()
for(id in unique(dat$human_id)) {
cat("new_id")
TR_bayes_modelling[[id]] <- list()
tdat <- subset(dat,human_id == id)
TR_bayes_modelling[[id]] <- DEoptim(fn=naive_bayes, lower = c(0,0), upper = c(1,1), data=tdat, opp_strategy_vec = c("level0","level1","level2") ,return_value = "-2loglik", opp_mod_transfer = TRUE, control=list(trace = FALSE, parallelType=1,parVar = c("best_response")))
TR_bayes_modelling[[id]] <- optim(c(0.1,0.1),fn=naive_bayes,gr = NULL, data=tdat,opp_strategy_vec = c("level0","level1","level2"),return_value = "-2loglik", opp_mod_transfer = TRUE,lower = c(0.01,0.01), upper = c(0.99,0.99), method="L-BFGS-B")
}
# Fitting a bayesiam model WITH TRANSFER of opp strat distribution between games
TR_bayes_modelling <- list()
for(id in unique(dat$human_id)) {
cat("new_id")
TR_bayes_modelling[[id]] <- list()
tdat <- subset(dat,human_id == id)
# TR_bayes_modelling[[id]] <- DEoptim(fn=naive_bayes, lower = c(0,0), upper = c(1,1), data=tdat, opp_strategy_vec = c("level0","level1","level2") ,return_value = "-2loglik", opp_mod_transfer = TRUE, control=list(trace = FALSE, parallelType=1,parVar = c("best_response")))
TR_bayes_modelling[[id]] <- optim(c(0.1,0.1),fn=naive_bayes,gr = NULL, data=tdat,opp_strategy_vec = c("level0","level1","level2"),return_value = "-2loglik", opp_mod_transfer = TRUE,lower = c(0.01,0.01), upper = c(0.99,0.99), method="L-BFGS-B")
}
# Fitting a bayesiam model WITH TRANSFER of opp strat distribution between games
TR_bayes_modelling <- list()
for(id in unique(dat$human_id)) {
TR_bayes_modelling[[id]] <- list()
tdat <- subset(dat,human_id == id)
# TR_bayes_modelling[[id]] <- DEoptim(fn=naive_bayes, lower = c(0,0), upper = c(1,1), data=tdat, opp_strategy_vec = c("level0","level1","level2") ,return_value = "-2loglik", opp_mod_transfer = TRUE, control=list(trace = FALSE, parallelType=1,parVar = c("best_response")))
TR_bayes_modelling[[id]] <- optim(c(0.1,0.1),fn=naive_bayes,gr = NULL, data=tdat,opp_strategy_vec = c("level0","level1","level2"),return_value = "-2loglik", opp_mod_transfer = TRUE,lower = c(0.01,0.01), upper = c(0.99,0.99), method="L-BFGS-B")
}
save(TR_bayes_modelling,file="TR_bayes_modelling.RData")
NT_bayes_modelling <- list()
for(id in unique(dat$human_id)) {
NT_bayes_modelling[[id]] <- list()
tdat <- subset(dat,human_id == id)
NT_bayes_modelling[[id]] <- DEoptim(fn=naive_bayes, lower = c(0.0,0.0), upper = c(1.0,1.0), data=tdat, opp_strategy_vec = c("level0","level1","level2"),return_value = "-2loglik", opp_mod_transfer = FALSE, control=list(trace = FALSE, parallelType=0,parVar = c("best_response")))
#   NT_bayes_modelling[[id]] <- optim(c(0.1,0.1),fn=naive_bayes,gr = NULL, data=tdat,opp_strategy_vec = c("level0","level1","level2"),return_value = "-2loglik", opp_mod_transfer = FALSE ,lower = c(0.01,0.01), upper = c(0.99,0.99), method="L-BFGS-B")
}
NT_bayes_modelling <- list()
for(id in unique(dat$human_id)) {
NT_bayes_modelling[[id]] <- list()
tdat <- subset(dat,human_id == id)
# NT_bayes_modelling[[id]] <- DEoptim(fn=naive_bayes, lower = c(0.0,0.0), upper = c(1.0,1.0), data=tdat, opp_strategy_vec = c("level0","level1","level2"),return_value = "-2loglik", opp_mod_transfer = FALSE, control=list(trace = FALSE, parallelType=0,parVar = c("best_response")))
NT_bayes_modelling[[id]] <- optim(c(0.1,0.1),fn=naive_bayes,gr = NULL, data=tdat,opp_strategy_vec = c("level0","level1","level2"),return_value = "-2loglik", opp_mod_transfer = FALSE ,lower = c(0.01,0.01), upper = c(0.99,0.99), method="L-BFGS-B")
}
View(optim_EWA)
View(optim_EWA)
install.packages("optimParallel")
