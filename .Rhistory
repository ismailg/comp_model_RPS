# EWA with states
"EWA_states_BIC" = EWA_states_modelling[[id]]$optim$bestval + 1*log(150),
"EWA_states_Lambda" = EWA_states_modelling[[id]]$optim$bestmem[1]
#
# # MBM
#  # MBM BIC
# "MBM_BIC" = MBM_modelling[[id]]$optim$bestval + 2*log(150),
#  # BEta parameter inverse temp in softmax
# "MBM_beta" = MBM_modelling[[id]]$optim$bestmem[1],
# "MBM_alpha" = MBM_modelling[[id]]$optim$bestmem[2]
))
}
dat <- read.csv("data20180719.csv")
#dat <- read.csv("test_data.csv")
# using some functions from the 'tidyverse' (also for me to get use to them ;-)
library(tidyr)
library(dplyr)
library(DEoptim)
library(optimParallel)
library(ggpubr)
# create a new data.frame in a 'wide format'
# widedata <- dat %>%
#   unite(game_block,game,block) %>% # this creates a new variable which combines game and block
#     group_by(human_id,condition,game_block) %>% # let the functions know you want to separate things by ID, condition, and game_block
#       summarize(mean_score = mean(score)) %>% # compute average score (i.e wins - losses)
#         spread(game_block,mean_score) # reformat in the 'wide' format
# # save the data file as a .csv to use in e.g. SPSS
# write.csv(widedata,row.names=FALSE,file="scores_wide.csv")
# read in the various files which
rps_predict_opp <- read.csv("rps_predict_opp.csv")
fwg_predict_opp <- read.csv("fwg_predict_opp.csv")
numbers_predict_opp <- read.csv("numbers_predict_opp.csv")
# transform 'winner' variable in numeric score
dat$score <- recode(dat$winner, human = 1, tie = 0, ai = -1)
# create a new variable 'block' with round 1...25 = block 1 and round 26...50 as block 2
dat$block <- as.numeric(cut(dat$round,2))
# recode actions to make them equal to the codes in these files
dat$h_action <- recode(dat$human_action,"rock" = "R", "paper" = "P", "scissors" = "S", "fire" = "F", "water" = "W", "grass" = "G", "one" = "1", "two" = "2", "three" = "3", "four" = "4", "five" = "5")
dat$a_action <- recode(dat$ai_action,"rock" = "R", "paper" = "P", "scissors" = "S", "fire" = "F", "water" = "W", "grass" = "G", "one" = "1", "two" = "2", "three" = "3", "four" = "4", "five" = "5")
write.csv(dat,file = "exp1_data.csv", row.names = FALSE)
# logit tranformation
my_logit <- function(x) {
ret <- log(x/(1-x))
ret[x==0] <- -Inf
ret[x==1] <- Inf
return(ret)
}
# inverse logit transformation
my_logistic <- function(x) {
ret <- 1/(1+exp(-x))
ret[x == -Inf] <- 0.0
ret[x == Inf] <- 1.0
return(ret)
}
# Function to produce best reponse to ai_action
best_response <- function(game,ai_action){
if (game == "rps"){
if (ai_action == "R") {return("P")}
else if (ai_action == "P") {return("S")}
else if (ai_action == "S") {return("R")}
} else if (game == "fwg"){
if (ai_action == "F") {return("W")}
else if (ai_action == "W") {return("G")}
else if (ai_action == "G") {return("F")}
} else if (game == "numbers") {
if (ai_action == "1") {return("2")}
else if (ai_action == "2") {return("3")}
else if (ai_action == "3") {return("4")}
else if (ai_action == "4") {return("5")}
else if (ai_action == "5") {return("1")}
}
}
exp1_ToM <- function(par,data,opp_strategy_vec,return_value,opp_mod_transfer) {
# dat = data subset for one participant
# opp_strategy_vec = vector of possible opponent strtegies, model assumes humans restrict opp strategy space to vector   c("level0","level1","level2")
# return = -2logLik
# or "likelihood_by_trial" vector  (for later plotting, etc)
# opp_mod_transfer is a boolean. True if distribution of opponent strategies is kept across games. False otherwise.
# theta = parameter, probability computer will play its best response to what it thinks human is. Truth = 90%. in [0,1].
# eps: parameter controlling noise in human choice. Probability human will DEVIATE from its best response. In [0,1].
theta <- par[1]
eps <- par[2]
num_strat = length(opp_strategy_vec)
# Load tables predicting oppponent move
rps_predict_opp <- read.csv("rps_predict_opp.csv")
fwg_predict_opp <- read.csv("fwg_predict_opp.csv")
numbers_predict_opp <- read.csv("numbers_predict_opp.csv")
#lik_opp is a vector that holds and update probability distribution of opp strategy given actions.
lik_opp <- matrix(0.0,num_strat, nrow(data))
# Initiate prior vector as uniform
opp_prior_vec <-rep(1/num_strat, num_strat)
lik_hum <- matrix(0.0,nrow(data))
# br_hum is vector that stores best responses of human to actions taken by each level-k ai opponent at the round.
br_hum <- rep(NA,num_strat)
for(t in 1:nrow(data)) {
t_game <- data[t,"game"]
pred_file_opp <- switch(as.character(t_game),rps = rps_predict_opp,fwg = fwg_predict_opp, numbers = numbers_predict_opp)
if(t_game == "numbers") nopts <- 5 else nopts <- 3
if(data[t,"round"] == 1) {
# first round is uniform prediction
pred_opp <- NA
lik_hum[t] <- 1/nopts
## KEY CODE FOR LEARNING TRANSFER !! (if no OM transfer, reset prior to uniform)
if (!(opp_mod_transfer)) {
opp_prior_vec <- rep(1/num_strat, num_strat)
lik_opp[,t] <- opp_prior_vec
}
# Rounds after first
} else {
# get prediction of opponent action from CSV files
for (strategy in opp_strategy_vec) {
k = match(strategy,opp_strategy_vec)
pred_opp <- as.character(filter(pred_file_opp, pred_file_opp$human_previous == as.character(data[t-1,"h_action"]) & pred_file_opp$computer_previous == as.character(data[t-1,"a_action"]))[[strategy]])
# Given opponent action predicted, what would be human action best response for each opp strat
br_hum[[k]] <- best_response(t_game,as.character(pred_opp))
# Multiply prior by likelihood of observation to get posterior. Done here ot take advantage of For loop.
if(as.character(data[t,"a_action"]) == pred_opp) {
lik_opp[k,t] <- (theta + (1-theta)/nopts)*opp_prior_vec[k]
} else {
lik_opp[k,t] <- ((1-theta)/nopts)*opp_prior_vec[k]
}
}
# Get which opponent strategy human current actn maps to (if index = 0 then human current action is br to level-0 comp_strat...)
indices <- which(br_hum %in% as.character(data[t,"h_action"]))
# THEN likelihood of current human action is just prior on opponent vec (haven't updated priors with curr opp act yet)
# if action is not predicted by any level-k OM, assume human chooses randomly with prob eps
if(length(indices) == 0){
lik_hum[t] <- eps/nopts
# if same br action for multiple possible ai opponents, add probabilities
} else {
lik_hum[t] <- sum(opp_prior_vec[indices])*(1-eps) + eps/nopts
}
# Standardising the probabilities and updating prior
lik_opp[,t] <- lik_opp[,t]/sum(lik_opp[,t])
opp_prior_vec <- lik_opp[,t]
}
# for debugging uncomment the line below
#cat(as.character(pred_opp),as.character(data[t,"a_action"]),lik_opp[,t],"\n")
}
if(return_value == "-2loglik") {
ret <- -2*sum(log(lik_hum))
if(is.infinite(ret) || is.nan(ret)) {
return(1e+300)
} else {
return(ret)
}
}
if(return_value == "likelihood_by_trial") return(lik_hum)
}
# data = subset(dat,human_id == "38VxtUSv_h6RR5-tAAA2")
# exp1_ToM(c(0.9,0.99),data,c("level0","level1","level2"),"-2loglik",FALSE)
# load("exp1_ToM_TR.RData")
# load("exp1_ToM_NT.RData")
# load("QL_modelling.RData")
# load("QL_states_modelling.RData")
# load("EWA_modelling.RData")
# load("EWA_self_modelling.RData")
# load("MBM_modelling.RData")
# load("EWA_states_modelling.RData")
All_results <- data.frame()
for(id in unique(dat$human_id)) {
All_results <- rbind(All_results,
data.frame(
"ID" = id,
"condition" = dat[dat$human_id==id,"condition"][1],
"Random_BIC" = -2*(100*log(1/3) + 50*log(1/5)),
# Bayesian updating with/without transfer
"Bayes_Tr_BIC" = exp1_ToM_TR[[id]]$value + 2*log(150),
"Bayes_No_Tr_BIC" = exp1_ToM_NT[[id]]$value+ 2*log(150),
# Theta is the parameter governing AI stochasticity. Truth is 0.9
"theta_transfer" = exp1_ToM_TR[[id]]$par[1],
"theta_no_transfer" = exp1_ToM_NT[[id]]$par[1],
# Epsilone is parameter showing cases where human deviates from predictions about opponent (lower better)
"eps_transfer" = exp1_ToM_TR[[id]]$par[2],
"eps_no_transfer" = exp1_ToM_NT[[id]]$par[2],
# Q-Learning
"QL_BIC" = QL_modelling[[id]]$value + 2*log(150),
# beta ->  inverse temperature parameter in softmax choice function
"QL_Beta" = QL_modelling[[id]]$par[1],
# alpha -> learning rate in QL update
"QL_alpha" = QL_modelling[[id]]$par[2],
# Q-learning with last round states
"QL_states_BIC" = QL_states_modelling[[id]]$optim$bestval + 2*log(150),
# beta ->  inverse temperature parameter in softmax choice function
"QL_states_Beta" = QL_states_modelling[[id]]$optim$bestmem[1],
# alpha -> learning rate in QL update
"QL_states_alpha" = QL_states_modelling[[id]]$optim$bestmem[2],
# Parametric EWA
# Parametric EWA BIC
"EWA_BIC" = EWA_modelling[[id]]$optim$bestval + 4*log(150),
"EWA_2LL" = EWA_modelling[[id]]$optim$bestval,
# Phi is depreciation of past attractions
"EWA_Phi" = EWA_modelling[[id]]$optim$bestmem[1],
# Delta is weight of foregone payoffs vs actual payoffs
"EWA_Delta" = EWA_modelling[[id]]$optim$bestmem[2],
# Rho is depreciation of the experience measure N(t)
"EWA_Rho" = EWA_modelling[[id]]$optim$bestmem[3],
#Lambda is a parameter of the softmax choice function (inverse Temperature)
"EWA_Lambda" = EWA_modelling[[id]]$optim$bestmem[4],
# Self-Tuning EWA (only 1 parameter)
# Parametric EWA BIC
"EWA_self_2LL" = EWA_self_modelling[[id]]$optim$bestval,
"EWA_self_BIC" = EWA_self_modelling[[id]]$optim$bestval + 1*log(150),
#Lambda is a parameter of the softmax choice function (inverse Temperature)
"EWA_self_Lambda" = EWA_self_modelling[[id]]$optim$bestmem[1],
# EWA with states
"EWA_states_BIC" = EWA_states_modelling[[id]]$optim$bestval + 1*log(150),
"EWA_states_Lambda" = EWA_states_modelling[[id]]$optim$bestmem[1]
#
# # MBM
#  # MBM BIC
# "MBM_BIC" = MBM_modelling[[id]]$optim$bestval + 2*log(150),
#  # BEta parameter inverse temp in softmax
# "MBM_beta" = MBM_modelling[[id]]$optim$bestmem[1],
# "MBM_alpha" = MBM_modelling[[id]]$optim$bestmem[2]
))
}
exp1_ToM_TR <- list()
for(id in unique(dat$human_id)) {
exp1_ToM_TR[[id]] <- list()
tdat <- subset(dat,human_id == id)
# exp1_ToM_TR[[id]] <- DEoptim(fn=exp1_ToM, lower = c(0,0), upper = c(1,1), data=tdat, opp_strategy_vec = c("level0","level1","level2") ,return_value = "-2loglik", opp_mod_transfer = TRUE, control=list(trace = FALSE, parallelType=1,parVar = c("best_response")))
exp1_ToM_TR[[id]] <- optim(c(0.1,0.1),fn=exp1_ToM,gr = NULL, data=tdat,opp_strategy_vec = c("level0","level1","level2"),return_value = "-2loglik", opp_mod_transfer = TRUE,lower = c(0.01,0.01), upper = c(0.99,0.99), method="L-BFGS-B")
}
save(exp1_ToM_TR,file="exp1_ToM_TR.RData")
# load("exp1_ToM_TR.RData")
# load("exp1_ToM_NT.RData")
# load("QL_modelling.RData")
# load("QL_states_modelling.RData")
# load("EWA_modelling.RData")
# load("EWA_self_modelling.RData")
# load("MBM_modelling.RData")
# load("EWA_states_modelling.RData")
All_results <- data.frame()
for(id in unique(dat$human_id)) {
All_results <- rbind(All_results,
data.frame(
"ID" = id,
"condition" = dat[dat$human_id==id,"condition"][1],
"Random_BIC" = -2*(100*log(1/3) + 50*log(1/5)),
# Bayesian updating with/without transfer
"Bayes_Tr_BIC" = exp1_ToM_TR[[id]]$value + 2*log(150),
"Bayes_No_Tr_BIC" = exp1_ToM_NT[[id]]$value+ 2*log(150),
# Theta is the parameter governing AI stochasticity. Truth is 0.9
"theta_transfer" = exp1_ToM_TR[[id]]$par[1],
"theta_no_transfer" = exp1_ToM_NT[[id]]$par[1],
# Epsilone is parameter showing cases where human deviates from predictions about opponent (lower better)
"eps_transfer" = exp1_ToM_TR[[id]]$par[2],
"eps_no_transfer" = exp1_ToM_NT[[id]]$par[2],
# Q-Learning
"QL_BIC" = QL_modelling[[id]]$value + 2*log(150),
# beta ->  inverse temperature parameter in softmax choice function
"QL_Beta" = QL_modelling[[id]]$par[1],
# alpha -> learning rate in QL update
"QL_alpha" = QL_modelling[[id]]$par[2],
# Q-learning with last round states
"QL_states_BIC" = QL_states_modelling[[id]]$optim$bestval + 2*log(150),
# beta ->  inverse temperature parameter in softmax choice function
"QL_states_Beta" = QL_states_modelling[[id]]$optim$bestmem[1],
# alpha -> learning rate in QL update
"QL_states_alpha" = QL_states_modelling[[id]]$optim$bestmem[2],
# Parametric EWA
# Parametric EWA BIC
"EWA_BIC" = EWA_modelling[[id]]$optim$bestval + 4*log(150),
"EWA_2LL" = EWA_modelling[[id]]$optim$bestval,
# Phi is depreciation of past attractions
"EWA_Phi" = EWA_modelling[[id]]$optim$bestmem[1],
# Delta is weight of foregone payoffs vs actual payoffs
"EWA_Delta" = EWA_modelling[[id]]$optim$bestmem[2],
# Rho is depreciation of the experience measure N(t)
"EWA_Rho" = EWA_modelling[[id]]$optim$bestmem[3],
#Lambda is a parameter of the softmax choice function (inverse Temperature)
"EWA_Lambda" = EWA_modelling[[id]]$optim$bestmem[4],
# Self-Tuning EWA (only 1 parameter)
# Parametric EWA BIC
"EWA_self_2LL" = EWA_self_modelling[[id]]$optim$bestval,
"EWA_self_BIC" = EWA_self_modelling[[id]]$optim$bestval + 1*log(150),
#Lambda is a parameter of the softmax choice function (inverse Temperature)
"EWA_self_Lambda" = EWA_self_modelling[[id]]$optim$bestmem[1],
# EWA with states
"EWA_states_BIC" = EWA_states_modelling[[id]]$optim$bestval + 1*log(150),
"EWA_states_Lambda" = EWA_states_modelling[[id]]$optim$bestmem[1]
#
# # MBM
#  # MBM BIC
# "MBM_BIC" = MBM_modelling[[id]]$optim$bestval + 2*log(150),
#  # BEta parameter inverse temp in softmax
# "MBM_beta" = MBM_modelling[[id]]$optim$bestmem[1],
# "MBM_alpha" = MBM_modelling[[id]]$optim$bestmem[2]
))
}
load("exp1_ToM_TR.RData")
load("exp1_ToM_NT.RData")
load("QL_modelling.RData")
load("QL_states_modelling.RData")
load("EWA_modelling.RData")
load("EWA_self_modelling.RData")
load("MBM_modelling.RData")
load("EWA_states_modelling.RData")
All_results <- data.frame()
for(id in unique(dat$human_id)) {
All_results <- rbind(All_results,
data.frame(
"ID" = id,
"condition" = dat[dat$human_id==id,"condition"][1],
"Random_BIC" = -2*(100*log(1/3) + 50*log(1/5)),
# Bayesian updating with/without transfer
"Bayes_Tr_BIC" = exp1_ToM_TR[[id]]$value + 2*log(150),
"Bayes_No_Tr_BIC" = exp1_ToM_NT[[id]]$value + 2*log(150),
# Theta is the parameter governing AI stochasticity. Truth is 0.9
"theta_transfer" = exp1_ToM_TR[[id]]$par[1],
"theta_no_transfer" = exp1_ToM_NT[[id]]$par[1],
# Epsilone is parameter showing cases where human deviates from predictions about opponent (lower better)
"eps_transfer" = exp1_ToM_TR[[id]]$par[2],
"eps_no_transfer" = exp1_ToM_NT[[id]]$par[2],
# Q-Learning
"QL_BIC" = QL_modelling[[id]]$value + 2*log(150),
# beta ->  inverse temperature parameter in softmax choice function
"QL_Beta" = QL_modelling[[id]]$par[1],
# alpha -> learning rate in QL update
"QL_alpha" = QL_modelling[[id]]$par[2],
# Q-learning with last round states
"QL_states_BIC" = QL_states_modelling[[id]]$optim$bestval + 2*log(150),
# beta ->  inverse temperature parameter in softmax choice function
"QL_states_Beta" = QL_states_modelling[[id]]$optim$bestmem[1],
# alpha -> learning rate in QL update
"QL_states_alpha" = QL_states_modelling[[id]]$optim$bestmem[2],
# Parametric EWA
# Parametric EWA BIC
"EWA_BIC" = EWA_modelling[[id]]$optim$bestval + 4*log(150),
"EWA_2LL" = EWA_modelling[[id]]$optim$bestval,
# Phi is depreciation of past attractions
"EWA_Phi" = EWA_modelling[[id]]$optim$bestmem[1],
# Delta is weight of foregone payoffs vs actual payoffs
"EWA_Delta" = EWA_modelling[[id]]$optim$bestmem[2],
# Rho is depreciation of the experience measure N(t)
"EWA_Rho" = EWA_modelling[[id]]$optim$bestmem[3],
#Lambda is a parameter of the softmax choice function (inverse Temperature)
"EWA_Lambda" = EWA_modelling[[id]]$optim$bestmem[4],
# Self-Tuning EWA (only 1 parameter)
# Parametric EWA BIC
"EWA_self_2LL" = EWA_self_modelling[[id]]$optim$bestval,
"EWA_self_BIC" = EWA_self_modelling[[id]]$optim$bestval + 1*log(150),
#Lambda is a parameter of the softmax choice function (inverse Temperature)
"EWA_self_Lambda" = EWA_self_modelling[[id]]$optim$bestmem[1],
# EWA with states
"EWA_states_BIC" = EWA_states_modelling[[id]]$optim$bestval + 1*log(150),
"EWA_states_Lambda" = EWA_states_modelling[[id]]$optim$bestmem[1]
#
# # MBM
#  # MBM BIC
# "MBM_BIC" = MBM_modelling[[id]]$optim$bestval + 2*log(150),
#  # BEta parameter inverse temp in softmax
# "MBM_beta" = MBM_modelling[[id]]$optim$bestmem[1],
# "MBM_alpha" = MBM_modelling[[id]]$optim$bestmem[2]
))
}
write.csv(All_results,file="All_results.csv",row.names = FALSE)
All_comp_results <- read.csv(file="../All_results.csv")
exp1_comp_table <- table(All_comp_results[, "condition"],c("random","ToM_BT","ToM_NBT","QL", "QL_states","EWA","S_EWA","EWA_states", "MBM")[apply(All_comp_results[,c("Random_BIC","Bayes_Tr_BIC","Bayes_No_Tr_BIC","QL_BIC","QL_states_BIC","EWA_BIC","EWA_self_BIC","EWA_states_BIC","MBM_BIC")],1,which.min)])
View(All_results)
All_comp_results <- read.csv(file="../All_results.csv")
exp1_comp_table <- table(All_comp_results[, "condition"],c("random","ToM_BT","ToM_NBT","QL", "QL_states","EWA","S_EWA","EWA_states", "MBM")[apply(All_comp_results[,c("Random_BIC","Bayes_Tr_BIC","Bayes_No_Tr_BIC","QL_BIC","QL_states_BIC","EWA_BIC","EWA_self_BIC","EWA_states_BIC","MBM_BIC")],1,which.min)])
View(All_comp_results)
All_comp_results <- read.csv(file="../All_results.csv")
exp1_comp_table <- table(All_comp_results[, "condition"],c("Random","ToM_BT","ToM_NBT","QL", "QL_states","EWA","S_EWA","EWA_states", "MBM")[apply(All_comp_results[,c("Random_BIC","Bayes_Tr_BIC","Bayes_No_Tr_BIC","QL_BIC","QL_states_BIC","EWA_BIC","EWA_self_BIC","EWA_states_BIC","MBM_BIC")],1,which.min)])
All_comp_results <- read.csv(file="../All_results.csv")
exp1_comp_table <- table(All_comp_results[, "condition"],c("Random","ToM_BT","ToM_NBT","QL", "QL_states","EWA","S_EWA","EWA_states", "MBM")[apply(All_comp_results[,c("Random_BIC","Bayes_Tr_BIC","Bayes_No_Tr_BIC","QL_BIC","QL_states_BIC","EWA_BIC","EWA_self_BIC","EWA_states_BIC")],1,which.min)])
#write.csv(exp1_comp_table ,file="exp1_comp_table ",row.names = TRUE)
kable(exp1_comp_table)
exp1_dat = read.csv("../exp1_data.csv")
# exp1_model_comp = read.csv("../exp1_model_comp.csv")
exp1_model_comp <- data.frame()
for(id in unique(exp1_dat$human_id)) {
tdat <- subset(exp1_dat,human_id == id)
tot_score <- sum(tdat$score)
tot_time <- sum(tdat$human_rt)
early_dat <- subset(tdat,between(tdat$round,2,6) & (game =="fwg"))
#early_dat <- subset(tdat,between(tdat$round,2,6) & (game =="fwg" | game =="numbers") )
tr_score <- sum(early_dat$score)
id_results <- subset(All_comp_results, ID == id)
min_BIC <- apply(id_results[,c("Random_BIC","Bayes_Tr_BIC","Bayes_No_Tr_BIC","QL_BIC","QL_states_BIC","EWA_BIC","EWA_self_BIC")],1,min)
best_model <- c("Random","ToM_BT","ToM_NBT","QL", "QL_states","EWA","S_EWA")[apply(id_results[,c("Random_BIC","Bayes_Tr_BIC","Bayes_No_Tr_BIC","QL_BIC","QL_states_BIC","EWA_BIC","EWA_self_BIC")],1,which.min)]
#
exp1_model_comp <- rbind(exp1_model_comp,
data.frame(
"human_id" = id,
"condition" = exp1_dat[exp1_dat$human_id==id,"condition"][1],
"Early_game_score" = tr_score,
"Total_score" = tot_score,
"Best_model" = best_model,
"Total_time" = sum(tdat$human_rt),
"TR_minus_NT_BIC" = id_results[,"Bayes_Tr_BIC"] - id_results[,"Bayes_No_Tr_BIC"],
"Rand_minus_best_BIC" =  id_results[,"Random_BIC"] - min_BIC
))
}
datalist = list()
i = 0
new_dat <- setNames(data.frame(matrix(ncol = ncol(exp1_dat), nrow = 0)), colnames(exp1_dat))
for(id in unique(exp1_dat$human_id)) {
i <- i+1
tdat <- subset(exp1_dat,human_id == id)
tdat$part_num <- i
tdat <- within(tdat, acc_sum <- cumsum(tdat$score))
datalist[[i]] <- tdat
}
# Merge all datasets into one
new_dat <- dplyr::bind_rows(datalist)
# or new_dat <- data.table::rbindlist(datalist)
# Add column for time t
new_dat <- new_dat %>% group_by(exp1_dat$human_id) %>% mutate(t = row_number())
# Add best fitting model per participant
new_dat <- merge(new_dat, exp1_model_comp[, c("human_id", "Best_model")], by="human_id")
temp <- new_dat[,c("t","acc_sum","Best_model","condition","part_num")]
dat_by_model <- temp %>% group_by(Best_model,t) %>%
summarize(model_acc_sum = mean(acc_sum))
#knitr::include_graphics("../Report/images/exp1_comp_models.png", dpi = 108)
par(las=2) # make label text perpendicular to axis
par(mar=c(5,8,4,2)) # increase y-axis margin.
barplot(exp1_comp_table,
horiz =TRUE, # rotate barplot for better visibility
las=1, # change orientation x axis labels
cex.names=0.8, # text label size
legend = rownames(exp1_comp_table),
beside =TRUE,
xlab="Number of participants",
args.legend=list( # positioning of legend box
x=ncol(exp1_comp_table) + 4,
y=max(colSums(exp1_comp_table)) + 4,
bty = "n")
)
ggplot(data = dat_by_model, aes(x = t, y=model_acc_sum, group = Best_model)) +
geom_line(aes(color= Best_model))
ggplot(data = dat_by_model, aes(x = t, y=model_acc_sum, group = Best_model)) +
geom_line(aes(color= Best_model) +
xlab = " Round number"
ggplot(data = dat_by_model, aes(x = t, y=model_acc_sum, group = Best_model)) +
geom_line(aes(color= Best_model) +
xlab ("Round Number")
)
ggplot(data = dat_by_model, aes(x = t, y=model_acc_sum, group = Best_model),     xlab ("Round Number")) +
geom_line(aes(color= Best_model)
)
ggplot(data = dat_by_model, aes(x = t, y=model_acc_sum, group = Best_model), xlab("Round Number")) +
geom_line(aes(color= Best_model)
)
p5 <- ggplot(data = dat_by_model, aes(x = t, y=model_acc_sum, group = Best_model)) +
geom_line(aes(color= Best_model))
p5+ labs(x = "Round Number")
p5 <- ggplot(data = dat_by_model, aes(x = t, y=model_acc_sum, group = Best_model)) +
geom_line(aes(color= Best_model))
p5+ labs(color = "Best fitting model", x = "Round Number")
p8 <- ggplot(data = dat_by_model_2, aes(x = t, y=avg_acc_sum, group = Best_model_2)) +
geom_line(aes(color= Best_model_2)) +
scale_x_continuous(minor_breaks = seq(0 , 180, 10), breaks = seq(0, 180, 60))
p8 + labs(color = "Best fitting model", x = "Round Number", y="Accumulated score")
devtools::install_github("ropenscilabs/gramr")
library(papaja)
library(knitr)
library(citr)
library(bookdown)
# using some functions dplyr, ggpubr, PairedData and sjPlot. Need to be loaded.
library(tidyr)
library(dplyr)
library(MASS)
library(ggpubr)
library(afex)
library(PairedData)
library(multcompView)
library(lsmeans)
library(papaja)
library(knitr)
library(citr)
library(bookdown)
# using some functions dplyr, ggpubr, PairedData and sjPlot. Need to be loaded.
library(tidyr)
library(dplyr)
library(MASS)
library(ggpubr)
library(afex)
library(PairedData)
library(multcompView)
library(lsmeans)
library(gramr)
install.packages("V8")
library(papaja)
library(knitr)
library(citr)
library(bookdown)
# using some functions dplyr, ggpubr, PairedData and sjPlot. Need to be loaded.
library(tidyr)
library(dplyr)
library(MASS)
library(ggpubr)
library(afex)
library(PairedData)
library(multcompView)
library(lsmeans)
library(papaja)
require(knitr)
require(citr)
require(bookdown)
# using some functions dplyr, ggpubr, PairedData and sjPlot. Need to be loaded.
library(tidyr)
library(dplyr)
library(MASS)
library(ggpubr)
library(afex)
library(PairedData)
library(multcompView)
library(lsmeans)
install.packages("magick")
